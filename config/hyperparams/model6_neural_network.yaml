# Model 6: Neural Network (Dense Feed-Forward)
# Hybrid: Ruby preprocessing → Python NN → Ruby ensemble

architecture:
  layer1_units: [16, 32, 64]               # First hidden layer size (reduced for small datasets)
  layer2_units: [8, 16, 32]                # Second hidden layer size
  layer3_units: [0]                        # Third layer (0 = skip, recommended for <500 samples)
  dropout_rate: [0.3, 0.4, 0.5]            # Higher dropout prevents overfitting
  activation: ['relu', 'elu']              # Activation function

training:
  learning_rate: [0.001, 0.003, 0.01]      # Adam optimizer LR
  batch_size: [16, 32]                     # Smaller batches for small datasets
  epochs: [100, 200, 300]                  # Max epochs (early stopping used)
  patience: [15, 20]                       # Early stopping patience
  
regularization:
  l1_penalty: [0.0, 0.0001]               # L1 regularization
  l2_penalty: [0.001, 0.01]               # Stronger L2 for small datasets

feature_engineering:
  scaler: ['standard', 'minmax', 'robust'] # Feature scaling method
  polynomial_degree: [1, 2]                # Polynomial features (1=none, 2=quadratic)

# Optimization notes:
# - 2-layer network (layer3_units=0) recommended for datasets <500 samples
# - Higher dropout (0.4-0.5) prevents overfitting on small datasets  
# - Early stopping essential (patience=15-20)
# - Polynomial features add interactions (degree=2 creates x₁², x₂², x₁·x₂, etc.)
# - Scaler choice: standard (normal dist), minmax (bounded), robust (outliers)
# 
# Hockey-specific features (auto-generated if columns present):
# - Rolling averages (goals_last_5, goals_allowed_last_5)
# - Rest days between games
# - Goal differential metrics
# 
# Architecture validation:
# - Script warns if network too large for dataset (needs 10× samples per parameter)
# - For 82 NHL games (~100 samples): max layer1_units = 32, layer3_units = 0
# 
# Expected search space: 3×3×1×3×2×3×2×3×2×2×3×2 = 11,664 combinations
# (layer1×layer2×layer3×dropout×activation×lr×batch×epochs×patience×l1×l2×scaler×poly)
# Reduced from 419,904 for faster search on small datasets
# Recommended: random_search(50-100) for practical coverage
