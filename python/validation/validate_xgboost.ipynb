{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1145f36d",
   "metadata": {},
   "source": [
    "# XGBoost Model Validation\n",
    "\n",
    "Comprehensive validation tests for the XGBoost model.\n",
    "\n",
    "**Tests:**\n",
    "1. Basic functionality (fit, predict, evaluate)\n",
    "2. Hyperparameter effects\n",
    "3. Feature importance\n",
    "4. Regularization behavior\n",
    "5. Serialization (save/load)\n",
    "6. Cross-validation stability\n",
    "7. Edge cases and error handling\n",
    "8. Dual goal predictor\n",
    "\n",
    "Run this BEFORE using the model in production to catch bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d73b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"WARNING: XGBoost not installed. Some tests will be skipped.\")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Test tracking\n",
    "test_results = []\n",
    "\n",
    "def record_test(name, passed, message=\"\"):\n",
    "    status = \"✅ PASS\" if passed else \"❌ FAIL\"\n",
    "    test_results.append({'test': name, 'passed': passed, 'message': message})\n",
    "    print(f\"{status}: {name}\")\n",
    "    if message:\n",
    "        print(f\"       {message}\")\n",
    "\n",
    "print(f\"XGBoost available: {XGB_AVAILABLE}\")\n",
    "print(\"Validation setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619eebf",
   "metadata": {},
   "source": [
    "## Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e23d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic hockey-like test data\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "X_test = pd.DataFrame({\n",
    "    'home_win_pct': np.random.uniform(0.3, 0.7, n),\n",
    "    'away_win_pct': np.random.uniform(0.3, 0.7, n),\n",
    "    'home_goals_avg': np.random.uniform(2.5, 3.8, n),\n",
    "    'away_goals_avg': np.random.uniform(2.5, 3.8, n),\n",
    "    'home_goals_against_avg': np.random.uniform(2.2, 3.5, n),\n",
    "    'away_goals_against_avg': np.random.uniform(2.2, 3.5, n),\n",
    "    'home_pp_pct': np.random.uniform(0.15, 0.28, n),\n",
    "    'away_pp_pct': np.random.uniform(0.15, 0.28, n),\n",
    "    'home_rest_days': np.random.randint(1, 5, n),\n",
    "    'away_rest_days': np.random.randint(1, 5, n),\n",
    "})\n",
    "\n",
    "# Create realistic target with known relationships\n",
    "y_home = (\n",
    "    X_test['home_goals_avg'] * 0.4 +\n",
    "    (4 - X_test['away_goals_against_avg']) * 0.3 +\n",
    "    X_test['home_pp_pct'] * 5 +\n",
    "    0.3 +  # home advantage\n",
    "    np.random.normal(0, 0.5, n)\n",
    ").clip(0, 8).round().astype(int)\n",
    "\n",
    "y_away = (\n",
    "    X_test['away_goals_avg'] * 0.4 +\n",
    "    (4 - X_test['home_goals_against_avg']) * 0.3 +\n",
    "    X_test['away_pp_pct'] * 5 +\n",
    "    np.random.normal(0, 0.5, n)\n",
    ").clip(0, 8).round().astype(int)\n",
    "\n",
    "# Train/test split\n",
    "split_idx = int(n * 0.8)\n",
    "X_train, X_val = X_test.iloc[:split_idx], X_test.iloc[split_idx:]\n",
    "y_home_train, y_home_val = y_home[:split_idx], y_home[split_idx:]\n",
    "y_away_train, y_away_val = y_away[:split_idx], y_away[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Validation: {len(X_val)}\")\n",
    "print(f\"Home goals range: {y_home.min()} - {y_home.max()}\")\n",
    "print(f\"Away goals range: {y_away.min()} - {y_away.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c2802",
   "metadata": {},
   "source": [
    "## Test 1: Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ab393",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not XGB_AVAILABLE:\n",
    "    record_test(\"1. XGBoost import\", False, \"XGBoost not installed\")\n",
    "else:\n",
    "    # Test 1a: Model creation\n",
    "    try:\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        record_test(\"1a. Model creation\", True)\n",
    "    except Exception as e:\n",
    "        record_test(\"1a. Model creation\", False, str(e))\n",
    "\n",
    "    # Test 1b: Fit\n",
    "    try:\n",
    "        model.fit(X_train, y_home_train)\n",
    "        record_test(\"1b. Model fit\", True, f\"n_features={len(X_train.columns)}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"1b. Model fit\", False, str(e))\n",
    "\n",
    "    # Test 1c: Predict\n",
    "    try:\n",
    "        predictions = model.predict(X_val)\n",
    "        valid = len(predictions) == len(y_home_val) and not np.isnan(predictions).any()\n",
    "        record_test(\"1c. Model predict\", valid, f\"n_predictions={len(predictions)}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"1c. Model predict\", False, str(e))\n",
    "\n",
    "    # Test 1d: Evaluate\n",
    "    try:\n",
    "        rmse = np.sqrt(mean_squared_error(y_home_val, predictions))\n",
    "        mae = mean_absolute_error(y_home_val, predictions)\n",
    "        r2 = r2_score(y_home_val, predictions)\n",
    "        record_test(\"1d. Model evaluate\", True, f\"RMSE={rmse:.4f}, MAE={mae:.4f}, R²={r2:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"1d. Model evaluate\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb853f",
   "metadata": {},
   "source": [
    "## Test 2: Hyperparameter Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    # Test 2a: More trees should generally improve or maintain performance\n",
    "    try:\n",
    "        model_50 = xgb.XGBRegressor(n_estimators=50, max_depth=6, random_state=42)\n",
    "        model_200 = xgb.XGBRegressor(n_estimators=200, max_depth=6, random_state=42)\n",
    "        \n",
    "        model_50.fit(X_train, y_home_train)\n",
    "        model_200.fit(X_train, y_home_train)\n",
    "        \n",
    "        rmse_50 = np.sqrt(mean_squared_error(y_home_val, model_50.predict(X_val)))\n",
    "        rmse_200 = np.sqrt(mean_squared_error(y_home_val, model_200.predict(X_val)))\n",
    "        \n",
    "        # 200 trees should be similar or better\n",
    "        improved = rmse_200 <= rmse_50 * 1.1  # Allow 10% tolerance\n",
    "        record_test(\"2a. n_estimators effect\", improved, \n",
    "                   f\"50 trees: {rmse_50:.4f}, 200 trees: {rmse_200:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"2a. n_estimators effect\", False, str(e))\n",
    "\n",
    "    # Test 2b: max_depth control\n",
    "    try:\n",
    "        model_d3 = xgb.XGBRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "        model_d10 = xgb.XGBRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "        \n",
    "        model_d3.fit(X_train, y_home_train)\n",
    "        model_d10.fit(X_train, y_home_train)\n",
    "        \n",
    "        # Deeper trees often overfit\n",
    "        train_rmse_d3 = np.sqrt(mean_squared_error(y_home_train, model_d3.predict(X_train)))\n",
    "        train_rmse_d10 = np.sqrt(mean_squared_error(y_home_train, model_d10.predict(X_train)))\n",
    "        \n",
    "        deeper_fits_better = train_rmse_d10 <= train_rmse_d3\n",
    "        record_test(\"2b. max_depth effect on training\", deeper_fits_better,\n",
    "                   f\"depth=3 train RMSE: {train_rmse_d3:.4f}, depth=10: {train_rmse_d10:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"2b. max_depth effect on training\", False, str(e))\n",
    "\n",
    "    # Test 2c: Learning rate\n",
    "    try:\n",
    "        model_fast = xgb.XGBRegressor(n_estimators=100, learning_rate=0.3, random_state=42)\n",
    "        model_slow = xgb.XGBRegressor(n_estimators=100, learning_rate=0.01, random_state=42)\n",
    "        \n",
    "        model_fast.fit(X_train, y_home_train)\n",
    "        model_slow.fit(X_train, y_home_train)\n",
    "        \n",
    "        # Fast learning should fit training data better with same n_estimators\n",
    "        train_rmse_fast = np.sqrt(mean_squared_error(y_home_train, model_fast.predict(X_train)))\n",
    "        train_rmse_slow = np.sqrt(mean_squared_error(y_home_train, model_slow.predict(X_train)))\n",
    "        \n",
    "        record_test(\"2c. learning_rate effect\", train_rmse_fast < train_rmse_slow,\n",
    "                   f\"lr=0.3: {train_rmse_fast:.4f}, lr=0.01: {train_rmse_slow:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"2c. learning_rate effect\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ee197",
   "metadata": {},
   "source": [
    "## Test 3: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    try:\n",
    "        model = xgb.XGBRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
    "        model.fit(X_train, y_home_train)\n",
    "        \n",
    "        # Get feature importance\n",
    "        importance = model.feature_importances_\n",
    "        feature_imp = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Top features should include goals-related features\n",
    "        top_features = feature_imp.head(3)['feature'].tolist()\n",
    "        has_goals_feature = any('goals' in f for f in top_features)\n",
    "        \n",
    "        record_test(\"3a. Feature importance extraction\", len(importance) == len(X_train.columns),\n",
    "                   f\"Top 3: {top_features}\")\n",
    "        \n",
    "        # Importance sums to 1 (normalized)\n",
    "        sum_importance = importance.sum()\n",
    "        record_test(\"3b. Importance normalization\", abs(sum_importance - 1.0) < 0.01,\n",
    "                   f\"Sum: {sum_importance:.4f}\")\n",
    "        \n",
    "        print(\"\\nFeature Importance:\")\n",
    "        print(feature_imp.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        record_test(\"3. Feature importance\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25e5c3",
   "metadata": {},
   "source": [
    "## Test 4: Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f186c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    # Test L1 regularization (reg_alpha)\n",
    "    try:\n",
    "        model_no_reg = xgb.XGBRegressor(n_estimators=100, reg_alpha=0, reg_lambda=0, random_state=42)\n",
    "        model_l1 = xgb.XGBRegressor(n_estimators=100, reg_alpha=10, reg_lambda=0, random_state=42)\n",
    "        \n",
    "        model_no_reg.fit(X_train, y_home_train)\n",
    "        model_l1.fit(X_train, y_home_train)\n",
    "        \n",
    "        # L1 regularization should reduce overfitting\n",
    "        train_no_reg = np.sqrt(mean_squared_error(y_home_train, model_no_reg.predict(X_train)))\n",
    "        train_l1 = np.sqrt(mean_squared_error(y_home_train, model_l1.predict(X_train)))\n",
    "        \n",
    "        val_no_reg = np.sqrt(mean_squared_error(y_home_val, model_no_reg.predict(X_val)))\n",
    "        val_l1 = np.sqrt(mean_squared_error(y_home_val, model_l1.predict(X_val)))\n",
    "        \n",
    "        # Regularization should make training error higher (less overfit)\n",
    "        record_test(\"4a. L1 regularization (reg_alpha)\", train_l1 >= train_no_reg * 0.99,\n",
    "                   f\"No reg train: {train_no_reg:.4f}, L1 train: {train_l1:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"4a. L1 regularization\", False, str(e))\n",
    "\n",
    "    # Test L2 regularization (reg_lambda)\n",
    "    try:\n",
    "        model_l2 = xgb.XGBRegressor(n_estimators=100, reg_alpha=0, reg_lambda=10, random_state=42)\n",
    "        model_l2.fit(X_train, y_home_train)\n",
    "        \n",
    "        train_l2 = np.sqrt(mean_squared_error(y_home_train, model_l2.predict(X_train)))\n",
    "        \n",
    "        record_test(\"4b. L2 regularization (reg_lambda)\", True,\n",
    "                   f\"L2 train RMSE: {train_l2:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"4b. L2 regularization\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f65a2b",
   "metadata": {},
   "source": [
    "## Test 5: Serialization (Save/Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e84683",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    try:\n",
    "        # Train model\n",
    "        model = xgb.XGBRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
    "        model.fit(X_train, y_home_train)\n",
    "        original_pred = model.predict(X_val)\n",
    "        \n",
    "        # Save with pickle\n",
    "        with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as f:\n",
    "            pickle.dump(model, f)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        # Load\n",
    "        with open(temp_path, 'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "        \n",
    "        loaded_pred = loaded_model.predict(X_val)\n",
    "        \n",
    "        # Predictions should match\n",
    "        match = np.allclose(original_pred, loaded_pred)\n",
    "        record_test(\"5a. Pickle save/load\", match,\n",
    "                   f\"Max diff: {np.abs(original_pred - loaded_pred).max():.6f}\")\n",
    "        \n",
    "        # Clean up\n",
    "        os.unlink(temp_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        record_test(\"5a. Pickle save/load\", False, str(e))\n",
    "\n",
    "    # Test native XGBoost save/load\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(suffix='.json', delete=False) as f:\n",
    "            temp_path = f.name\n",
    "        \n",
    "        model.save_model(temp_path)\n",
    "        \n",
    "        loaded_model = xgb.XGBRegressor()\n",
    "        loaded_model.load_model(temp_path)\n",
    "        \n",
    "        native_pred = loaded_model.predict(X_val)\n",
    "        match = np.allclose(original_pred, native_pred)\n",
    "        \n",
    "        record_test(\"5b. Native XGBoost save/load\", match,\n",
    "                   f\"Max diff: {np.abs(original_pred - native_pred).max():.6f}\")\n",
    "        \n",
    "        os.unlink(temp_path)\n",
    "    except Exception as e:\n",
    "        record_test(\"5b. Native XGBoost save/load\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1c395",
   "metadata": {},
   "source": [
    "## Test 6: Cross-Validation Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    try:\n",
    "        model = xgb.XGBRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
    "        \n",
    "        # 5-fold cross-validation\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(model, X_test, y_home, cv=kfold, \n",
    "                                    scoring='neg_root_mean_squared_error')\n",
    "        \n",
    "        mean_rmse = -cv_scores.mean()\n",
    "        std_rmse = cv_scores.std()\n",
    "        \n",
    "        # Check stability (std should be reasonable relative to mean)\n",
    "        cv_ratio = std_rmse / mean_rmse\n",
    "        is_stable = cv_ratio < 0.3  # CV shouldn't vary more than 30%\n",
    "        \n",
    "        record_test(\"6. Cross-validation stability\", is_stable,\n",
    "                   f\"RMSE: {mean_rmse:.4f} (+/- {std_rmse:.4f}), CV ratio: {cv_ratio:.2%}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"6. Cross-validation stability\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2467ad",
   "metadata": {},
   "source": [
    "## Test 7: Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    # Test 7a: Single sample prediction\n",
    "    try:\n",
    "        model = xgb.XGBRegressor(n_estimators=50, random_state=42)\n",
    "        model.fit(X_train, y_home_train)\n",
    "        \n",
    "        single_pred = model.predict(X_val.iloc[[0]])\n",
    "        record_test(\"7a. Single sample prediction\", len(single_pred) == 1,\n",
    "                   f\"Prediction: {single_pred[0]:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"7a. Single sample prediction\", False, str(e))\n",
    "\n",
    "    # Test 7b: Missing features (should fail)\n",
    "    try:\n",
    "        X_missing = X_val.drop(columns=['home_win_pct'])\n",
    "        pred = model.predict(X_missing)\n",
    "        record_test(\"7b. Missing feature handling\", False, \"Should have raised error\")\n",
    "    except Exception as e:\n",
    "        record_test(\"7b. Missing feature handling\", True, \"Correctly raised error\")\n",
    "\n",
    "    # Test 7c: Empty prediction set\n",
    "    try:\n",
    "        empty_pred = model.predict(X_val.iloc[:0])\n",
    "        record_test(\"7c. Empty prediction set\", len(empty_pred) == 0)\n",
    "    except Exception as e:\n",
    "        record_test(\"7c. Empty prediction set\", False, str(e))\n",
    "\n",
    "    # Test 7d: Predictions should be reasonable\n",
    "    try:\n",
    "        all_pred = model.predict(X_test)\n",
    "        min_pred, max_pred = all_pred.min(), all_pred.max()\n",
    "        \n",
    "        # Goals should be in reasonable range (not negative, not > 15)\n",
    "        reasonable = min_pred >= -1 and max_pred <= 15\n",
    "        record_test(\"7d. Reasonable prediction range\", reasonable,\n",
    "                   f\"Range: [{min_pred:.2f}, {max_pred:.2f}]\")\n",
    "    except Exception as e:\n",
    "        record_test(\"7d. Reasonable prediction range\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7803b",
   "metadata": {},
   "source": [
    "## Test 8: Dual Goal Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    # Test training separate models for home and away goals\n",
    "    try:\n",
    "        home_model = xgb.XGBRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
    "        away_model = xgb.XGBRegressor(n_estimators=100, max_depth=6, random_state=42)\n",
    "        \n",
    "        home_model.fit(X_train, y_home_train)\n",
    "        away_model.fit(X_train, y_away_train)\n",
    "        \n",
    "        home_pred = home_model.predict(X_val)\n",
    "        away_pred = away_model.predict(X_val)\n",
    "        \n",
    "        home_rmse = np.sqrt(mean_squared_error(y_home_val, home_pred))\n",
    "        away_rmse = np.sqrt(mean_squared_error(y_away_val, away_pred))\n",
    "        \n",
    "        # Combined RMSE\n",
    "        all_pred = np.concatenate([home_pred, away_pred])\n",
    "        all_actual = np.concatenate([y_home_val, y_away_val])\n",
    "        combined_rmse = np.sqrt(mean_squared_error(all_actual, all_pred))\n",
    "        \n",
    "        record_test(\"8a. Dual model training\", True,\n",
    "                   f\"Home RMSE: {home_rmse:.4f}, Away RMSE: {away_rmse:.4f}\")\n",
    "        record_test(\"8b. Combined performance\", combined_rmse < 2.0,\n",
    "                   f\"Combined RMSE: {combined_rmse:.4f}\")\n",
    "    except Exception as e:\n",
    "        record_test(\"8. Dual goal predictor\", False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e8b49",
   "metadata": {},
   "source": [
    "## Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f416cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" XGBOOST VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_df = pd.DataFrame(test_results)\n",
    "passed = results_df['passed'].sum()\n",
    "total = len(results_df)\n",
    "\n",
    "print(f\"\\nPassed: {passed}/{total} ({passed/total*100:.1f}%)\")\n",
    "\n",
    "if passed < total:\n",
    "    print(\"\\n❌ FAILED TESTS:\")\n",
    "    for _, row in results_df[~results_df['passed']].iterrows():\n",
    "        print(f\"   - {row['test']}: {row['message']}\")\n",
    "else:\n",
    "    print(\"\\n✅ All tests passed!\")\n",
    "\n",
    "# Show all results\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
