{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8035756",
   "metadata": {},
   "source": [
    "# Model 1: Baseline Models - Validation Tests\n",
    "\n",
    "This notebook validates that all baseline models work correctly and produce sensible predictions.\n",
    "\n",
    "## Validation Tests\n",
    "\n",
    "| Test | Description | Pass Criteria |\n",
    "|------|-------------|---------------|\n",
    "| 1. Sanity Check | Predictions within valid range | 0 ≤ goals ≤ 15 |\n",
    "| 2. Consistency | Same input → same output | Deterministic |\n",
    "| 3. Fit Required | Can't predict before fitting | Raises error |\n",
    "| 4. Team Distinction | Different teams → different predictions | TeamMean varies |\n",
    "| 5. Home Advantage | Home teams score more on average | home_goals > away_goals |\n",
    "| 6. Evaluation | Metrics computed correctly | RMSE > 0 |\n",
    "| 7. Edge Cases | Handle missing teams gracefully | Uses defaults |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2adcf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent for imports\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-contained baseline model classes for validation\n",
    "\n",
    "COLUMN_ALIASES = {\n",
    "    'home_team': ['home_team', 'home', 'team_home', 'h_team'],\n",
    "    'away_team': ['away_team', 'away', 'team_away', 'a_team', 'visitor'],\n",
    "    'home_goals': ['home_goals', 'home_score', 'h_goals', 'goals_home'],\n",
    "    'away_goals': ['away_goals', 'away_score', 'a_goals', 'goals_away'],\n",
    "}\n",
    "\n",
    "def get_value(game, field, default=None):\n",
    "    aliases = COLUMN_ALIASES.get(field, [field])\n",
    "    for alias in aliases:\n",
    "        if alias in game:\n",
    "            val = game[alias]\n",
    "            if pd.isna(val):\n",
    "                return default\n",
    "            return val\n",
    "    return default\n",
    "\n",
    "def get_column(df, field):\n",
    "    aliases = COLUMN_ALIASES.get(field, [field])\n",
    "    for alias in aliases:\n",
    "        if alias in df.columns:\n",
    "            return alias\n",
    "    return None\n",
    "\n",
    "\n",
    "class BaselineModel:\n",
    "    def __init__(self, params=None):\n",
    "        self.params = params or {}\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def evaluate(self, games_df):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before evaluation\")\n",
    "        from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "        home_preds, home_actuals = [], []\n",
    "        for _, game in games_df.iterrows():\n",
    "            home_pred, _ = self.predict_goals(game)\n",
    "            home_preds.append(home_pred)\n",
    "            home_actuals.append(get_value(game, 'home_goals', 0))\n",
    "        rmse = mean_squared_error(home_actuals, home_preds, squared=False)\n",
    "        mae = mean_absolute_error(home_actuals, home_preds)\n",
    "        return {'rmse': rmse, 'mae': mae}\n",
    "\n",
    "\n",
    "class GlobalMeanBaseline(BaselineModel):\n",
    "    def fit(self, games_df):\n",
    "        home_col = get_column(games_df, 'home_goals')\n",
    "        away_col = get_column(games_df, 'away_goals')\n",
    "        self.global_mean_home = games_df[home_col].mean()\n",
    "        self.global_mean_away = games_df[away_col].mean()\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict_goals(self, game):\n",
    "        return self.global_mean_home, self.global_mean_away\n",
    "\n",
    "\n",
    "class TeamMeanBaseline(BaselineModel):\n",
    "    def fit(self, games_df):\n",
    "        home_team_col = get_column(games_df, 'home_team')\n",
    "        away_team_col = get_column(games_df, 'away_team')\n",
    "        home_goals_col = get_column(games_df, 'home_goals')\n",
    "        away_goals_col = get_column(games_df, 'away_goals')\n",
    "        \n",
    "        goals_for, goals_against, games_played = {}, {}, {}\n",
    "        \n",
    "        for _, game in games_df.iterrows():\n",
    "            ht, at = game[home_team_col], game[away_team_col]\n",
    "            hg, ag = game[home_goals_col], game[away_goals_col]\n",
    "            \n",
    "            goals_for[ht] = goals_for.get(ht, 0) + hg\n",
    "            goals_against[ht] = goals_against.get(ht, 0) + ag\n",
    "            games_played[ht] = games_played.get(ht, 0) + 1\n",
    "            \n",
    "            goals_for[at] = goals_for.get(at, 0) + ag\n",
    "            goals_against[at] = goals_against.get(at, 0) + hg\n",
    "            games_played[at] = games_played.get(at, 0) + 1\n",
    "        \n",
    "        self.team_offense = {t: goals_for[t] / games_played[t] for t in games_played}\n",
    "        self.team_defense = {t: goals_against[t] / games_played[t] for t in games_played}\n",
    "        self.global_mean = games_df[home_goals_col].mean()\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict_goals(self, game):\n",
    "        ht = get_value(game, 'home_team')\n",
    "        at = get_value(game, 'away_team')\n",
    "        home_off = self.team_offense.get(ht, self.global_mean)\n",
    "        home_def = self.team_defense.get(ht, self.global_mean)\n",
    "        away_off = self.team_offense.get(at, self.global_mean)\n",
    "        away_def = self.team_defense.get(at, self.global_mean)\n",
    "        return (home_off + away_def) / 2, (away_off + home_def) / 2\n",
    "\n",
    "\n",
    "class HomeAwayBaseline(BaselineModel):\n",
    "    def fit(self, games_df):\n",
    "        home_team_col = get_column(games_df, 'home_team')\n",
    "        away_team_col = get_column(games_df, 'away_team')\n",
    "        home_goals_col = get_column(games_df, 'home_goals')\n",
    "        away_goals_col = get_column(games_df, 'away_goals')\n",
    "        \n",
    "        home_goals_for, home_games = {}, {}\n",
    "        \n",
    "        for _, game in games_df.iterrows():\n",
    "            ht = game[home_team_col]\n",
    "            hg = game[home_goals_col]\n",
    "            home_goals_for[ht] = home_goals_for.get(ht, 0) + hg\n",
    "            home_games[ht] = home_games.get(ht, 0) + 1\n",
    "        \n",
    "        self.home_offense = {t: home_goals_for[t]/home_games[t] for t in home_games}\n",
    "        self.global_mean = games_df[home_goals_col].mean()\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict_goals(self, game):\n",
    "        ht = get_value(game, 'home_team')\n",
    "        home_pred = self.home_offense.get(ht, self.global_mean)\n",
    "        return home_pred, self.global_mean\n",
    "\n",
    "\n",
    "class MovingAverageBaseline(BaselineModel):\n",
    "    def __init__(self, params=None):\n",
    "        super().__init__(params)\n",
    "        self.window = self.params.get('window', 5)\n",
    "    \n",
    "    def fit(self, games_df):\n",
    "        home_team_col = get_column(games_df, 'home_team')\n",
    "        away_team_col = get_column(games_df, 'away_team')\n",
    "        home_goals_col = get_column(games_df, 'home_goals')\n",
    "        away_goals_col = get_column(games_df, 'away_goals')\n",
    "        \n",
    "        self.team_history = {}\n",
    "        \n",
    "        for _, game in games_df.iterrows():\n",
    "            ht, at = game[home_team_col], game[away_team_col]\n",
    "            hg, ag = game[home_goals_col], game[away_goals_col]\n",
    "            \n",
    "            if ht not in self.team_history: self.team_history[ht] = []\n",
    "            if at not in self.team_history: self.team_history[at] = []\n",
    "            \n",
    "            self.team_history[ht].append((hg, ag))\n",
    "            self.team_history[at].append((ag, hg))\n",
    "        \n",
    "        self.global_mean = games_df[home_goals_col].mean()\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def _get_recent_avg(self, team):\n",
    "        if team not in self.team_history or len(self.team_history[team]) == 0:\n",
    "            return self.global_mean, self.global_mean\n",
    "        recent = self.team_history[team][-self.window:]\n",
    "        return np.mean([g[0] for g in recent]), np.mean([g[1] for g in recent])\n",
    "    \n",
    "    def predict_goals(self, game):\n",
    "        ht, at = get_value(game, 'home_team'), get_value(game, 'away_team')\n",
    "        home_off, home_def = self._get_recent_avg(ht)\n",
    "        away_off, away_def = self._get_recent_avg(at)\n",
    "        return (home_off + away_def) / 2, (away_off + home_def) / 2\n",
    "\n",
    "\n",
    "class WeightedHistoryBaseline(BaselineModel):\n",
    "    def __init__(self, params=None):\n",
    "        super().__init__(params)\n",
    "        self.decay = self.params.get('decay', 0.9)\n",
    "    \n",
    "    def fit(self, games_df):\n",
    "        home_goals_col = get_column(games_df, 'home_goals')\n",
    "        self.global_mean = games_df[home_goals_col].mean()\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict_goals(self, game):\n",
    "        return self.global_mean, self.global_mean\n",
    "\n",
    "\n",
    "class PoissonBaseline(BaselineModel):\n",
    "    def fit(self, games_df):\n",
    "        home_goals_col = get_column(games_df, 'home_goals')\n",
    "        away_goals_col = get_column(games_df, 'away_goals')\n",
    "        self.league_avg = games_df[home_goals_col].mean()\n",
    "        self.home_factor = games_df[home_goals_col].mean() / max(games_df[away_goals_col].mean(), 0.01)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict_goals(self, game):\n",
    "        return self.league_avg * self.home_factor, self.league_avg / self.home_factor\n",
    "\n",
    "\n",
    "print(\"Baseline models loaded for validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5da2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Strong team scores more, weak team scores less\n",
    "test_data = pd.DataFrame([\n",
    "    {'home_team': 'Strong', 'away_team': 'Weak', 'home_goals': 5, 'away_goals': 1},\n",
    "    {'home_team': 'Strong', 'away_team': 'Average', 'home_goals': 4, 'away_goals': 2},\n",
    "    {'home_team': 'Average', 'away_team': 'Strong', 'home_goals': 2, 'away_goals': 4},\n",
    "    {'home_team': 'Weak', 'away_team': 'Strong', 'home_goals': 1, 'away_goals': 5},\n",
    "    {'home_team': 'Average', 'away_team': 'Weak', 'home_goals': 3, 'away_goals': 2},\n",
    "    {'home_team': 'Weak', 'away_team': 'Average', 'home_goals': 2, 'away_goals': 3},\n",
    "    {'home_team': 'Strong', 'away_team': 'Weak', 'home_goals': 6, 'away_goals': 0},\n",
    "    {'home_team': 'Strong', 'away_team': 'Average', 'home_goals': 4, 'away_goals': 3},\n",
    "])\n",
    "\n",
    "print(\"Test data created:\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c4e17",
   "metadata": {},
   "source": [
    "## Test 1: Sanity Check - Predictions Within Valid Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6882e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sanity_check():\n",
    "    \"\"\"Test that all predictions are within valid hockey goal range.\"\"\"\n",
    "    models = [\n",
    "        GlobalMeanBaseline(),\n",
    "        TeamMeanBaseline(),\n",
    "        HomeAwayBaseline(),\n",
    "        MovingAverageBaseline({'window': 3}),\n",
    "        PoissonBaseline()\n",
    "    ]\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(test_data)\n",
    "        \n",
    "        for _, game in test_data.iterrows():\n",
    "            home_pred, away_pred = model.predict_goals(game)\n",
    "            \n",
    "            # Goals should be non-negative\n",
    "            assert home_pred >= 0, f\"{model.__class__.__name__}: Negative home goals\"\n",
    "            assert away_pred >= 0, f\"{model.__class__.__name__}: Negative away goals\"\n",
    "            \n",
    "            # Goals should be reasonable (< 15 for hockey)\n",
    "            assert home_pred <= 15, f\"{model.__class__.__name__}: Home goals too high\"\n",
    "            assert away_pred <= 15, f\"{model.__class__.__name__}: Away goals too high\"\n",
    "    \n",
    "    return True\n",
    "\n",
    "try:\n",
    "    test_sanity_check()\n",
    "    print(\"✅ TEST 1 PASSED: All predictions within valid range [0, 15]\")\n",
    "except AssertionError as e:\n",
    "    print(f\"❌ TEST 1 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8c68c",
   "metadata": {},
   "source": [
    "## Test 2: Consistency - Same Input Produces Same Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9988b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_consistency():\n",
    "    \"\"\"Test that predictions are deterministic.\"\"\"\n",
    "    model = TeamMeanBaseline()\n",
    "    model.fit(test_data)\n",
    "    \n",
    "    game = test_data.iloc[0]\n",
    "    \n",
    "    # Get prediction multiple times\n",
    "    pred1 = model.predict_goals(game)\n",
    "    pred2 = model.predict_goals(game)\n",
    "    pred3 = model.predict_goals(game)\n",
    "    \n",
    "    assert pred1 == pred2 == pred3, \"Predictions should be identical\"\n",
    "    return True\n",
    "\n",
    "try:\n",
    "    test_consistency()\n",
    "    print(\"✅ TEST 2 PASSED: Predictions are consistent (deterministic)\")\n",
    "except AssertionError as e:\n",
    "    print(f\"❌ TEST 2 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f346f9",
   "metadata": {},
   "source": [
    "## Test 3: Fit Required - Can't Predict Before Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit_required():\n",
    "    \"\"\"Test that evaluation fails if model not fitted.\"\"\"\n",
    "    model = TeamMeanBaseline()\n",
    "    \n",
    "    try:\n",
    "        model.evaluate(test_data)\n",
    "        return False  # Should have raised error\n",
    "    except RuntimeError:\n",
    "        return True  # Expected behavior\n",
    "\n",
    "try:\n",
    "    if test_fit_required():\n",
    "        print(\"✅ TEST 3 PASSED: Model raises error when not fitted\")\n",
    "    else:\n",
    "        print(\"❌ TEST 3 FAILED: No error raised for unfitted model\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ TEST 3 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a9f016",
   "metadata": {},
   "source": [
    "## Test 4: Team Distinction - Different Teams Get Different Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef214e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_team_distinction():\n",
    "    \"\"\"Test that TeamMean distinguishes between teams.\"\"\"\n",
    "    model = TeamMeanBaseline()\n",
    "    model.fit(test_data)\n",
    "    \n",
    "    # Create games with different matchups\n",
    "    game1 = pd.Series({'home_team': 'Strong', 'away_team': 'Weak'})\n",
    "    game2 = pd.Series({'home_team': 'Weak', 'away_team': 'Strong'})\n",
    "    \n",
    "    pred1 = model.predict_goals(game1)\n",
    "    pred2 = model.predict_goals(game2)\n",
    "    \n",
    "    # Strong team should be predicted to score more\n",
    "    assert pred1[0] > pred2[0], \"Strong home should score more than Weak home\"\n",
    "    \n",
    "    return True\n",
    "\n",
    "try:\n",
    "    test_team_distinction()\n",
    "    print(\"✅ TEST 4 PASSED: Model distinguishes between teams\")\n",
    "except AssertionError as e:\n",
    "    print(f\"❌ TEST 4 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8e298",
   "metadata": {},
   "source": [
    "## Test 5: Home Advantage - Home Teams Score More on Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_home_advantage():\n",
    "    \"\"\"Test that GlobalMean captures home advantage in data.\"\"\"\n",
    "    model = GlobalMeanBaseline()\n",
    "    model.fit(test_data)\n",
    "    \n",
    "    # Our test data has home advantage\n",
    "    avg_home = test_data['home_goals'].mean()\n",
    "    avg_away = test_data['away_goals'].mean()\n",
    "    \n",
    "    # Model should capture this\n",
    "    assert model.global_mean_home == avg_home, \"Home mean should match data\"\n",
    "    assert model.global_mean_away == avg_away, \"Away mean should match data\"\n",
    "    \n",
    "    return True\n",
    "\n",
    "try:\n",
    "    test_home_advantage()\n",
    "    print(\"✅ TEST 5 PASSED: Model captures home/away goal averages correctly\")\n",
    "except AssertionError as e:\n",
    "    print(f\"❌ TEST 5 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad31ca3",
   "metadata": {},
   "source": [
    "## Test 6: Evaluation - Metrics Computed Correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043eecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation():\n",
    "    \"\"\"Test that evaluation returns valid metrics.\"\"\"\n",
    "    model = GlobalMeanBaseline()\n",
    "    model.fit(test_data)\n",
    "    \n",
    "    metrics = model.evaluate(test_data)\n",
    "    \n",
    "    # Check metrics exist and are valid\n",
    "    assert 'rmse' in metrics, \"RMSE should be in metrics\"\n",
    "    assert 'mae' in metrics, \"MAE should be in metrics\"\n",
    "    assert metrics['rmse'] >= 0, \"RMSE should be non-negative\"\n",
    "    assert metrics['mae'] >= 0, \"MAE should be non-negative\"\n",
    "    assert metrics['rmse'] >= metrics['mae'], \"RMSE should be >= MAE\"\n",
    "    \n",
    "    return True\n",
    "\n",
    "try:\n",
    "    test_evaluation()\n",
    "    print(\"✅ TEST 6 PASSED: Evaluation metrics computed correctly\")\n",
    "except AssertionError as e:\n",
    "    print(f\"❌ TEST 6 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f982870",
   "metadata": {},
   "source": [
    "## Test 7: Edge Cases - Handle Missing Teams Gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d492928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_edge_cases():\n",
    "    \"\"\"Test handling of unknown teams.\"\"\"\n",
    "    model = TeamMeanBaseline()\n",
    "    model.fit(test_data)\n",
    "    \n",
    "    # Unknown team\n",
    "    unknown_game = pd.Series({\n",
    "        'home_team': 'NewTeam',  # Not in training data\n",
    "        'away_team': 'Strong'\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        home_pred, away_pred = model.predict_goals(unknown_game)\n",
    "        \n",
    "        # Should use global mean as fallback\n",
    "        assert home_pred > 0, \"Unknown team should get global mean\"\n",
    "        assert away_pred > 0, \"Known team should get valid prediction\"\n",
    "        \n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    if test_edge_cases():\n",
    "        print(\"✅ TEST 7 PASSED: Unknown teams handled gracefully with defaults\")\n",
    "    else:\n",
    "        print(\"❌ TEST 7 FAILED: Error handling unknown teams\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ TEST 7 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f5188",
   "metadata": {},
   "source": [
    "## Test 8: Column Flexibility - Different Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84532a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_column_flexibility():\n",
    "    \"\"\"Test that models work with different column naming conventions.\"\"\"\n",
    "    # Alternative column names\n",
    "    alt_data = pd.DataFrame([\n",
    "        {'home': 'A', 'away': 'B', 'home_score': 3, 'away_score': 2},\n",
    "        {'home': 'B', 'away': 'A', 'home_score': 2, 'away_score': 4},\n",
    "        {'home': 'A', 'away': 'B', 'home_score': 5, 'away_score': 1},\n",
    "    ])\n",
    "    \n",
    "    model = TeamMeanBaseline()\n",
    "    model.fit(alt_data)\n",
    "    \n",
    "    game = alt_data.iloc[0]\n",
    "    home_pred, away_pred = model.predict_goals(game)\n",
    "    \n",
    "    assert home_pred > 0, \"Should work with 'home' column\"\n",
    "    assert away_pred > 0, \"Should work with 'away' column\"\n",
    "    \n",
    "    return True\n",
    "\n",
    "try:\n",
    "    test_column_flexibility()\n",
    "    print(\"✅ TEST 8 PASSED: Model works with alternative column names\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ TEST 8 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714361f",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eda846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests and summarize\n",
    "tests = [\n",
    "    (\"Sanity Check\", test_sanity_check),\n",
    "    (\"Consistency\", test_consistency),\n",
    "    (\"Fit Required\", test_fit_required),\n",
    "    (\"Team Distinction\", test_team_distinction),\n",
    "    (\"Home Advantage\", test_home_advantage),\n",
    "    (\"Evaluation\", test_evaluation),\n",
    "    (\"Edge Cases\", test_edge_cases),\n",
    "    (\"Column Flexibility\", test_column_flexibility),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BASELINE MODEL VALIDATION SUMMARY\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "passed = 0\n",
    "failed = 0\n",
    "\n",
    "for name, test_func in tests:\n",
    "    try:\n",
    "        result = test_func()\n",
    "        if result:\n",
    "            print(f\"✅ {name}\")\n",
    "            passed += 1\n",
    "        else:\n",
    "            print(f\"❌ {name}\")\n",
    "            failed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {name}: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Results: {passed} passed, {failed} failed\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if failed == 0:\n",
    "    print(\"\\n ALL TESTS PASSED - Baseline models are validated\")\n",
    "else:\n",
    "    print(f\"\\n  {failed} test(s) failed - Review issues above\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
