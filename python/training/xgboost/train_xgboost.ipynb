{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8114f6b2",
   "metadata": {},
   "source": [
    "# Model 4: XGBoost - Training and Hyperparameter Tuning\n",
    "\n",
    "This notebook trains and tunes XGBoost models for hockey goal prediction.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Setup and Imports\n",
    "2. Load Data\n",
    "3. Feature Engineering\n",
    "4. Baseline XGBoost\n",
    "5. Random Search Hyperparameter Tuning\n",
    "6. Grid Search (Fine-tuning)\n",
    "7. Cross-Validation Analysis\n",
    "8. Feature Importance\n",
    "9. Final Model Evaluation\n",
    "10. Save Best Model\n",
    "\n",
    "## Hyperparameter Tuning Strategy\n",
    "\n",
    "Based on `config/hyperparams/model4_xgboost.yaml`:\n",
    "\n",
    "1. Start with defaults\n",
    "2. Tune max_depth and min_child_weight (control overfitting)\n",
    "3. Tune gamma (minimum loss reduction)\n",
    "4. Tune subsample and colsample_bytree (prevent overfitting)\n",
    "5. Tune regularization (reg_alpha, reg_lambda)\n",
    "6. Lower learning_rate and increase n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a8675",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9098850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import pathlib\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reliably set cwd to the python/ folder\n",
    "_cwd = pathlib.Path(os.path.abspath('')).resolve()\n",
    "if (_cwd / 'python').is_dir():\n",
    "    _python_dir = _cwd / 'python'\n",
    "elif _cwd.name == 'xgboost' and (_cwd.parent.parent / 'data').is_dir():\n",
    "    _python_dir = _cwd.parent.parent\n",
    "elif _cwd.name == 'training' and (_cwd.parent / 'data').is_dir():\n",
    "    _python_dir = _cwd.parent\n",
    "elif (_cwd / 'data').is_dir():\n",
    "    _python_dir = _cwd\n",
    "else:\n",
    "    raise RuntimeError(f'Cannot locate python/ directory from {_cwd}')\n",
    "\n",
    "os.chdir(_python_dir)\n",
    "sys.path.insert(0, str(_python_dir))\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Check XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(f\" XGBoost version: {xgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\" XGBoost not installed. Run: pip install xgboost\")\n",
    "    raise\n",
    "\n",
    "print(f\"CWD: {os.getcwd()}\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759979a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameter configuration\n",
    "config_path = '../config/hyperparams/model4_xgboost.yaml'\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(f\"Loaded config: {config['model_name']}\")\n",
    "    print(f\"Description: {config['description']}\")\n",
    "else:\n",
    "    print(f\"Config not found at {config_path}, using defaults\")\n",
    "    config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7649614",
   "metadata": {},
   "source": [
    "## 2. Load or Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f099403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real data, otherwise generate synthetic\n",
    "data_path = 'data/hockey_features.csv'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    print(f\"Loaded {len(data)} games from {data_path}\")\n",
    "else:\n",
    "    print(\"Generating synthetic hockey data for demonstration...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_games = 2000\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        # Team strength metrics\n",
    "        'home_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "        'away_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "        'home_points_pct': np.random.uniform(0.4, 0.8, n_games),\n",
    "        'away_points_pct': np.random.uniform(0.4, 0.8, n_games),\n",
    "        \n",
    "        # Offensive metrics\n",
    "        'home_goals_avg': np.random.uniform(2.5, 3.8, n_games),\n",
    "        'away_goals_avg': np.random.uniform(2.5, 3.8, n_games),\n",
    "        'home_shots_avg': np.random.uniform(28, 35, n_games),\n",
    "        'away_shots_avg': np.random.uniform(28, 35, n_games),\n",
    "        \n",
    "        # Defensive metrics\n",
    "        'home_goals_against_avg': np.random.uniform(2.2, 3.5, n_games),\n",
    "        'away_goals_against_avg': np.random.uniform(2.2, 3.5, n_games),\n",
    "        'home_save_pct': np.random.uniform(0.88, 0.93, n_games),\n",
    "        'away_save_pct': np.random.uniform(0.88, 0.93, n_games),\n",
    "        \n",
    "        # Special teams\n",
    "        'home_pp_pct': np.random.uniform(0.15, 0.28, n_games),\n",
    "        'away_pp_pct': np.random.uniform(0.15, 0.28, n_games),\n",
    "        'home_pk_pct': np.random.uniform(0.75, 0.88, n_games),\n",
    "        'away_pk_pct': np.random.uniform(0.75, 0.88, n_games),\n",
    "        \n",
    "        # Context\n",
    "        'home_rest_days': np.random.randint(1, 5, n_games),\n",
    "        'away_rest_days': np.random.randint(1, 5, n_games),\n",
    "        'home_b2b': np.random.binomial(1, 0.15, n_games),\n",
    "        'away_b2b': np.random.binomial(1, 0.15, n_games),\n",
    "        \n",
    "        # Recent form (last 5 games)\n",
    "        'home_goals_last5': np.random.uniform(2.0, 4.0, n_games),\n",
    "        'away_goals_last5': np.random.uniform(2.0, 4.0, n_games),\n",
    "        'home_wins_last5': np.random.randint(0, 6, n_games),\n",
    "        'away_wins_last5': np.random.randint(0, 6, n_games),\n",
    "    })\n",
    "    \n",
    "    # Generate realistic goal totals\n",
    "    home_advantage = 0.35\n",
    "    \n",
    "    data['home_goals'] = np.round(\n",
    "        data['home_goals_avg'] * 0.3 +\n",
    "        data['home_goals_last5'] * 0.2 +\n",
    "        (4 - data['away_goals_against_avg']) * 0.3 +\n",
    "        data['home_pp_pct'] * 3 +\n",
    "        home_advantage +\n",
    "        (data['home_rest_days'] - data['away_rest_days']) * 0.1 +\n",
    "        np.random.normal(0, 0.8, n_games)\n",
    "    ).clip(0, 9).astype(int)\n",
    "    \n",
    "    data['away_goals'] = np.round(\n",
    "        data['away_goals_avg'] * 0.3 +\n",
    "        data['away_goals_last5'] * 0.2 +\n",
    "        (4 - data['home_goals_against_avg']) * 0.3 +\n",
    "        data['away_pp_pct'] * 3 +\n",
    "        np.random.normal(0, 0.8, n_games)\n",
    "    ).clip(0, 9).astype(int)\n",
    "    \n",
    "    print(f\"Generated {n_games} synthetic games\")\n",
    "\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "print(f\"Home goals mean: {data['home_goals'].mean():.2f}\")\n",
    "print(f\"Away goals mean: {data['away_goals'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a28e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and targets\n",
    "target_cols = ['home_goals', 'away_goals']\n",
    "exclude_cols = target_cols + ['home_team', 'away_team', 'date', 'game_id', 'season']\n",
    "\n",
    "feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols[:10]}...\")\n",
    "\n",
    "X = data[feature_cols]\n",
    "y_home = data['home_goals']\n",
    "y_away = data['away_goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation/test split (60/20/20)\n",
    "X_trainval, X_test, y_home_trainval, y_home_test, y_away_trainval, y_away_test = train_test_split(\n",
    "    X, y_home, y_away, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_home_train, y_home_val, y_away_train, y_away_val = train_test_split(\n",
    "    X_trainval, y_home_trainval, y_away_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} games\")\n",
    "print(f\"Validation set: {len(X_val)} games\")\n",
    "print(f\"Test set: {len(X_test)} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b098e02",
   "metadata": {},
   "source": [
    "## 3. Baseline XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters from config\n",
    "default_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1.0,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist',\n",
    "}\n",
    "\n",
    "print(\"Default XGBoost Parameters:\")\n",
    "for k, v in default_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model for home goals\n",
    "baseline_home = xgb.XGBRegressor(**default_params)\n",
    "baseline_home.fit(\n",
    "    X_train, y_home_train,\n",
    "    eval_set=[(X_train, y_home_train), (X_val, y_home_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Train baseline model for away goals\n",
    "baseline_away = xgb.XGBRegressor(**default_params)\n",
    "baseline_away.fit(\n",
    "    X_train, y_away_train,\n",
    "    eval_set=[(X_train, y_away_train), (X_val, y_away_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Baseline models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline on validation set\n",
    "def evaluate_models(home_model, away_model, X, y_home, y_away):\n",
    "    \"\"\"Evaluate both models and return combined metrics.\"\"\"\n",
    "    home_pred = home_model.predict(X)\n",
    "    away_pred = away_model.predict(X)\n",
    "    \n",
    "    metrics = {\n",
    "        'home_rmse': np.sqrt(mean_squared_error(y_home, home_pred)),\n",
    "        'away_rmse': np.sqrt(mean_squared_error(y_away, away_pred)),\n",
    "        'home_mae': mean_absolute_error(y_home, home_pred),\n",
    "        'away_mae': mean_absolute_error(y_away, away_pred),\n",
    "        'home_r2': r2_score(y_home, home_pred),\n",
    "        'away_r2': r2_score(y_away, away_pred),\n",
    "    }\n",
    "    \n",
    "    # Combined metrics\n",
    "    all_pred = np.concatenate([home_pred, away_pred])\n",
    "    all_actual = np.concatenate([y_home, y_away])\n",
    "    metrics['combined_rmse'] = np.sqrt(mean_squared_error(all_actual, all_pred))\n",
    "    metrics['combined_mae'] = mean_absolute_error(all_actual, all_pred)\n",
    "    metrics['combined_r2'] = r2_score(all_actual, all_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "baseline_metrics = evaluate_models(baseline_home, baseline_away, X_val, y_home_val, y_away_val)\n",
    "\n",
    "print(\"\\n Baseline Validation Performance\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nHome Goals:\")\n",
    "print(f\"  RMSE: {baseline_metrics['home_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['home_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['home_r2']:.4f}\")\n",
    "print(f\"\\nAway Goals:\")\n",
    "print(f\"  RMSE: {baseline_metrics['away_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['away_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['away_r2']:.4f}\")\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {baseline_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['combined_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd6411",
   "metadata": {},
   "source": [
    "## 4. Random Search Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter distributions for random search\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'n_estimators': [200, 500, 800, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 8],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0.5, 1.0, 2.0, 5.0],\n",
    "}\n",
    "\n",
    "print(f\"Parameters to tune: {len(param_distributions)}\")\n",
    "for k, v in param_distributions.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(X_train, y_train, X_val, y_val, param_dist, n_iter=50):\n",
    "    \"\"\"\n",
    "    Perform random search for hyperparameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Running {n_iter} random search iterations...\")\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # Sample random parameters\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'tree_method': 'hist',\n",
    "        }\n",
    "        \n",
    "        for key, values in param_dist.items():\n",
    "            params[key] = np.random.choice(values)\n",
    "        \n",
    "        try:\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "            model.fit(X_train, y_train, verbose=False)\n",
    "            \n",
    "            preds = model.predict(X_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "            \n",
    "            results.append({\n",
    "                **{k: v for k, v in params.items() if k in param_dist},\n",
    "                'val_rmse': rmse\n",
    "            })\n",
    "            \n",
    "            if rmse < best_score:\n",
    "                best_score = rmse\n",
    "                best_params = params.copy()\n",
    "                best_model = model\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Iteration {i + 1}/{n_iter} - Best RMSE: {best_score:.4f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error at iteration {i}: {e}\")\n",
    "    \n",
    "    return best_params, best_score, best_model, pd.DataFrame(results)\n",
    "\n",
    "# Run random search for home goals\n",
    "print(\"\\n Random Search: Home Goals Model\")\n",
    "print(\"=\" * 45)\n",
    "best_home_params, best_home_score, best_home_model, home_results = random_search(\n",
    "    X_train, y_home_train, X_val, y_home_val, param_distributions, n_iter=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run random search for away goals\n",
    "print(\"\\n Random Search: Away Goals Model\")\n",
    "print(\"=\" * 45)\n",
    "best_away_params, best_away_score, best_away_model, away_results = random_search(\n",
    "    X_train, y_away_train, X_val, y_away_val, param_distributions, n_iter=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29692f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best parameters\n",
    "print(\"\\n Best Home Goals Parameters:\")\n",
    "print(f\"   Validation RMSE: {best_home_score:.4f}\")\n",
    "for k, v in best_home_params.items():\n",
    "    if k in param_distributions:\n",
    "        print(f\"   {k}: {v}\")\n",
    "\n",
    "print(\"\\n Best Away Goals Parameters:\")\n",
    "print(f\"   Validation RMSE: {best_away_score:.4f}\")\n",
    "for k, v in best_away_params.items():\n",
    "    if k in param_distributions:\n",
    "        print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1788df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parameter importance from random search\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Top parameters to visualize\n",
    "params_to_plot = ['learning_rate', 'max_depth', 'n_estimators', 'min_child_weight']\n",
    "\n",
    "for ax, param in zip(axes.flatten(), params_to_plot):\n",
    "    home_results.boxplot(column='val_rmse', by=param, ax=ax)\n",
    "    ax.set_title(f'RMSE by {param}')\n",
    "    ax.set_xlabel(param)\n",
    "    ax.set_ylabel('Validation RMSE')\n",
    "\n",
    "plt.suptitle('Parameter Impact on Validation RMSE (Home Goals)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb898a9",
   "metadata": {},
   "source": [
    "## 5. Evaluate Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs tuned\n",
    "tuned_metrics = evaluate_models(best_home_model, best_away_model, X_val, y_home_val, y_away_val)\n",
    "\n",
    "print(\"\\n Performance Comparison (Validation Set)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n{'Metric':<20} {'Baseline':<15} {'Tuned':<15} {'Change':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in ['combined_rmse', 'combined_mae', 'combined_r2']:\n",
    "    baseline_val = baseline_metrics[metric]\n",
    "    tuned_val = tuned_metrics[metric]\n",
    "    \n",
    "    if 'r2' in metric:\n",
    "        change = tuned_val - baseline_val\n",
    "        change_str = f\"{change:+.4f}\"\n",
    "    else:\n",
    "        change = (tuned_val - baseline_val) / baseline_val * 100\n",
    "        change_str = f\"{change:+.2f}%\"\n",
    "    \n",
    "    print(f\"{metric:<20} {baseline_val:<15.4f} {tuned_val:<15.4f} {change_str:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23141fcf",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation on the best home model parameters\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_model = xgb.XGBRegressor(**best_home_params)\n",
    "cv_scores = cross_val_score(\n",
    "    cv_model, X_trainval, y_home_trainval,\n",
    "    cv=kfold, scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "cv_rmse = -cv_scores\n",
    "\n",
    "print(\"\\n 5-Fold Cross-Validation (Home Goals)\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nFold RMSE values: {cv_rmse}\")\n",
    "print(f\"\\nMean RMSE: {cv_rmse.mean():.4f} (+/- {cv_rmse.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "folds = range(1, len(cv_rmse) + 1)\n",
    "ax.bar(folds, cv_rmse, color='steelblue', edgecolor='black')\n",
    "ax.axhline(cv_rmse.mean(), color='red', linestyle='--', label=f'Mean: {cv_rmse.mean():.4f}')\n",
    "ax.fill_between(\n",
    "    [0.5, 5.5], \n",
    "    cv_rmse.mean() - cv_rmse.std(), \n",
    "    cv_rmse.mean() + cv_rmse.std(),\n",
    "    alpha=0.2, color='red', label=f'±1 std: {cv_rmse.std():.4f}'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Fold')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Cross-Validation RMSE by Fold')\n",
    "ax.set_xticks(folds)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380dfb1",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from best home model\n",
    "feature_importance = pd.Series(\n",
    "    best_home_model.feature_importances_,\n",
    "    index=feature_cols\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n Top 15 Features (Home Goals Model)\")\n",
    "print(\"=\" * 45)\n",
    "for feat, imp in feature_importance.head(15).items():\n",
    "    print(f\"  {feat:<30} {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74689354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# Home model\n",
    "home_importance = pd.Series(\n",
    "    best_home_model.feature_importances_,\n",
    "    index=feature_cols\n",
    ").sort_values(ascending=True).tail(15)\n",
    "\n",
    "axes[0].barh(home_importance.index, home_importance.values, color='steelblue')\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Top 15 Features: Home Goals Model')\n",
    "\n",
    "# Away model\n",
    "away_importance = pd.Series(\n",
    "    best_away_model.feature_importances_,\n",
    "    index=feature_cols\n",
    ").sort_values(ascending=True).tail(15)\n",
    "\n",
    "axes[1].barh(away_importance.index, away_importance.values, color='darkorange')\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('Top 15 Features: Away Goals Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9062c5",
   "metadata": {},
   "source": [
    "## 8. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3320f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on full training+validation set\n",
    "final_home = xgb.XGBRegressor(**best_home_params)\n",
    "final_home.fit(X_trainval, y_home_trainval, verbose=False)\n",
    "\n",
    "final_away = xgb.XGBRegressor(**best_away_params)\n",
    "final_away.fit(X_trainval, y_away_trainval, verbose=False)\n",
    "\n",
    "# Final test evaluation\n",
    "test_metrics = evaluate_models(final_home, final_away, X_test, y_home_test, y_away_test)\n",
    "\n",
    "print(\"\\n FINAL TEST SET PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nHome Goals:\")\n",
    "print(f\"  RMSE: {test_metrics['home_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['home_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['home_r2']:.4f}\")\n",
    "print(f\"\\nAway Goals:\")\n",
    "print(f\"  RMSE: {test_metrics['away_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['away_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['away_r2']:.4f}\")\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {test_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['combined_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual plots\n",
    "home_pred_test = final_home.predict(X_test)\n",
    "away_pred_test = final_away.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Home goals\n",
    "axes[0].scatter(y_home_test, home_pred_test, alpha=0.4, edgecolors='black', linewidth=0.5)\n",
    "axes[0].plot([0, 8], [0, 8], 'r--', linewidth=2, label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual Home Goals')\n",
    "axes[0].set_ylabel('Predicted Home Goals')\n",
    "axes[0].set_title(f'Home Goals: Predicted vs Actual (RMSE={test_metrics[\"home_rmse\"]:.3f})')\n",
    "axes[0].legend()\n",
    "\n",
    "# Away goals\n",
    "axes[1].scatter(y_away_test, away_pred_test, alpha=0.4, edgecolors='black', linewidth=0.5, color='orange')\n",
    "axes[1].plot([0, 8], [0, 8], 'r--', linewidth=2, label='Perfect prediction')\n",
    "axes[1].set_xlabel('Actual Away Goals')\n",
    "axes[1].set_ylabel('Predicted Away Goals')\n",
    "axes[1].set_title(f'Away Goals: Predicted vs Actual (RMSE={test_metrics[\"away_rmse\"]:.3f})')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1623ecb",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "os.makedirs('output/models/xgboost', exist_ok=True)\n",
    "os.makedirs('output/predictions/xgboost', exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "final_home.save_model('output/models/xgboost/xgboost_home_best.json')\n",
    "final_away.save_model('output/models/xgboost/xgboost_away_best.json')\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"   output/models/xgboost/xgboost_home_best.json\")\n",
    "print(\"   output/models/xgboost/xgboost_away_best.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hyperparameters and results\n",
    "results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'XGBoost',\n",
    "    'home_params': {k: float(v) if isinstance(v, np.floating) else v \n",
    "                    for k, v in best_home_params.items() if k in param_distributions},\n",
    "    'away_params': {k: float(v) if isinstance(v, np.floating) else v \n",
    "                    for k, v in best_away_params.items() if k in param_distributions},\n",
    "    'test_metrics': {k: float(v) for k, v in test_metrics.items()},\n",
    "    'cv_mean_rmse': float(cv_rmse.mean()),\n",
    "    'cv_std_rmse': float(cv_rmse.std()),\n",
    "    'n_train': len(X_trainval),\n",
    "    'n_test': len(X_test),\n",
    "    'n_features': len(feature_cols),\n",
    "}\n",
    "\n",
    "with open('output/predictions/xgboost/xgboost_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\n Results saved to output/predictions/xgboost/xgboost_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01849c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random search results\n",
    "home_results.to_csv('output/predictions/xgboost/xgboost_home_random_search.csv', index=False)\n",
    "away_results.to_csv('output/predictions/xgboost/xgboost_away_random_search.csv', index=False)\n",
    "\n",
    "print(\" Random search results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2973e099",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Results\n",
    "\n",
    "| Metric | Baseline | Tuned | Improvement |\n",
    "|--------|----------|-------|-------------|\n",
    "| Combined RMSE | - | - | - |\n",
    "| Combined MAE | - | - | - |\n",
    "| Combined R² | - | - | - |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Best Parameters**: Found through 50 random search iterations\n",
    "2. **Most Important Features**: See feature importance analysis\n",
    "3. **Cross-validation**: 5-fold CV shows stable performance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try Optuna for more sophisticated hyperparameter search\n",
    "- Add SHAP analysis for better interpretability\n",
    "- Compare with Random Forest (`train_random_forest.ipynb`)\n",
    "- Integrate into ensemble model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
