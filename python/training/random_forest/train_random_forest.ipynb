{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdd88bb",
   "metadata": {},
   "source": [
    "# Model 4: Random Forest - Training and Hyperparameter Tuning\n",
    "\n",
    "This notebook trains and tunes Random Forest models for hockey goal prediction.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Setup and Imports\n",
    "2. Load Data\n",
    "3. Baseline Random Forest\n",
    "4. Random Search Hyperparameter Tuning\n",
    "5. Grid Search (Fine-tuning)\n",
    "6. Cross-Validation Analysis\n",
    "7. Feature Importance\n",
    "8. Final Model Evaluation\n",
    "9. Save Best Model\n",
    "\n",
    "## Random Forest vs XGBoost\n",
    "\n",
    "- **Random Forest**: Bagging ensemble, parallel trees, less prone to overfitting\n",
    "- **XGBoost**: Boosting ensemble, sequential trees, often higher accuracy but needs more tuning\n",
    "- We use both in Model 4 to compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7e0f8",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a208bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reliably set cwd to the python/ folder\n",
    "_cwd = pathlib.Path(os.path.abspath('')).resolve()\n",
    "if (_cwd / 'python').is_dir():\n",
    "    _python_dir = _cwd / 'python'\n",
    "elif _cwd.name == 'random_forest' and (_cwd.parent.parent / 'data').is_dir():\n",
    "    _python_dir = _cwd.parent.parent\n",
    "elif _cwd.name == 'training' and (_cwd.parent / 'data').is_dir():\n",
    "    _python_dir = _cwd.parent\n",
    "elif (_cwd / 'data').is_dir():\n",
    "    _python_dir = _cwd\n",
    "else:\n",
    "    raise RuntimeError(f'Cannot locate python/ directory from {_cwd}')\n",
    "\n",
    "os.chdir(_python_dir)\n",
    "sys.path.insert(0, str(_python_dir))\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"CWD: {os.getcwd()}\")\n",
    "print(f\"Scikit-learn RandomForest ready\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbec551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameter configuration\n",
    "config_path = '../config/hyperparams/model4_random_forest.yaml'\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(f\"Loaded config: {config['model_name']}\")\n",
    "    print(f\"Description: {config['description']}\")\n",
    "else:\n",
    "    print(f\"Config not found at {config_path}, using defaults\")\n",
    "    config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b69f5c",
   "metadata": {},
   "source": [
    "## 2. Load or Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real data, otherwise generate synthetic\n",
    "data_path = 'data/hockey_features.csv'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    print(f\"Loaded {len(data)} games from {data_path}\")\n",
    "else:\n",
    "    print(\"Generating synthetic hockey data for demonstration...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_games = 2000\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        # Team strength metrics\n",
    "        'home_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "        'away_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "        'home_points_pct': np.random.uniform(0.4, 0.8, n_games),\n",
    "        'away_points_pct': np.random.uniform(0.4, 0.8, n_games),\n",
    "        \n",
    "        # Offensive metrics\n",
    "        'home_goals_avg': np.random.uniform(2.5, 3.8, n_games),\n",
    "        'away_goals_avg': np.random.uniform(2.5, 3.8, n_games),\n",
    "        'home_shots_avg': np.random.uniform(28, 35, n_games),\n",
    "        'away_shots_avg': np.random.uniform(28, 35, n_games),\n",
    "        \n",
    "        # Defensive metrics\n",
    "        'home_goals_against_avg': np.random.uniform(2.2, 3.5, n_games),\n",
    "        'away_goals_against_avg': np.random.uniform(2.2, 3.5, n_games),\n",
    "        'home_save_pct': np.random.uniform(0.88, 0.93, n_games),\n",
    "        'away_save_pct': np.random.uniform(0.88, 0.93, n_games),\n",
    "        \n",
    "        # Special teams\n",
    "        'home_pp_pct': np.random.uniform(0.15, 0.28, n_games),\n",
    "        'away_pp_pct': np.random.uniform(0.15, 0.28, n_games),\n",
    "        'home_pk_pct': np.random.uniform(0.75, 0.88, n_games),\n",
    "        'away_pk_pct': np.random.uniform(0.75, 0.88, n_games),\n",
    "        \n",
    "        # Context\n",
    "        'home_rest_days': np.random.randint(1, 5, n_games),\n",
    "        'away_rest_days': np.random.randint(1, 5, n_games),\n",
    "        'home_b2b': np.random.binomial(1, 0.15, n_games),\n",
    "        'away_b2b': np.random.binomial(1, 0.15, n_games),\n",
    "        \n",
    "        # Recent form (last 5 games)\n",
    "        'home_goals_last5': np.random.uniform(2.0, 4.0, n_games),\n",
    "        'away_goals_last5': np.random.uniform(2.0, 4.0, n_games),\n",
    "        'home_wins_last5': np.random.randint(0, 6, n_games),\n",
    "        'away_wins_last5': np.random.randint(0, 6, n_games),\n",
    "    })\n",
    "    \n",
    "    # Generate realistic goal totals\n",
    "    home_advantage = 0.35\n",
    "    \n",
    "    data['home_goals'] = np.round(\n",
    "        data['home_goals_avg'] * 0.3 +\n",
    "        data['home_goals_last5'] * 0.2 +\n",
    "        (4 - data['away_goals_against_avg']) * 0.3 +\n",
    "        data['home_pp_pct'] * 3 +\n",
    "        home_advantage +\n",
    "        (data['home_rest_days'] - data['away_rest_days']) * 0.1 +\n",
    "        np.random.normal(0, 0.8, n_games)\n",
    "    ).clip(0, 9).astype(int)\n",
    "    \n",
    "    data['away_goals'] = np.round(\n",
    "        data['away_goals_avg'] * 0.3 +\n",
    "        data['away_goals_last5'] * 0.2 +\n",
    "        (4 - data['home_goals_against_avg']) * 0.3 +\n",
    "        data['away_pp_pct'] * 3 +\n",
    "        np.random.normal(0, 0.8, n_games)\n",
    "    ).clip(0, 9).astype(int)\n",
    "    \n",
    "    print(f\"Generated {n_games} synthetic games\")\n",
    "\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "print(f\"Home goals mean: {data['home_goals'].mean():.2f}\")\n",
    "print(f\"Away goals mean: {data['away_goals'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and targets\n",
    "target_cols = ['home_goals', 'away_goals']\n",
    "exclude_cols = target_cols + ['home_team', 'away_team', 'date', 'game_id', 'season']\n",
    "\n",
    "feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols[:10]}...\")\n",
    "\n",
    "X = data[feature_cols]\n",
    "y_home = data['home_goals']\n",
    "y_away = data['away_goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0509d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation/test split (60/20/20)\n",
    "X_trainval, X_test, y_home_trainval, y_home_test, y_away_trainval, y_away_test = train_test_split(\n",
    "    X, y_home, y_away, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_home_train, y_home_val, y_away_train, y_away_val = train_test_split(\n",
    "    X_trainval, y_home_trainval, y_away_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} games\")\n",
    "print(f\"Validation set: {len(X_val)} games\")\n",
    "print(f\"Test set: {len(X_test)} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50fe4c",
   "metadata": {},
   "source": [
    "## 3. Baseline Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83687620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters from config or sensible defaults\n",
    "default_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': True,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "\n",
    "print(\"Default Random Forest Parameters:\")\n",
    "for k, v in default_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model for home goals\n",
    "baseline_home = RandomForestRegressor(**default_params)\n",
    "baseline_home.fit(X_train, y_home_train)\n",
    "\n",
    "# Train baseline model for away goals\n",
    "baseline_away = RandomForestRegressor(**default_params)\n",
    "baseline_away.fit(X_train, y_away_train)\n",
    "\n",
    "print(\"Baseline models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e24632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline on validation set\n",
    "def evaluate_models(home_model, away_model, X, y_home, y_away):\n",
    "    \"\"\"Evaluate both models and return combined metrics.\"\"\"\n",
    "    home_pred = home_model.predict(X)\n",
    "    away_pred = away_model.predict(X)\n",
    "    \n",
    "    metrics = {\n",
    "        'home_rmse': np.sqrt(mean_squared_error(y_home, home_pred)),\n",
    "        'away_rmse': np.sqrt(mean_squared_error(y_away, away_pred)),\n",
    "        'home_mae': mean_absolute_error(y_home, home_pred),\n",
    "        'away_mae': mean_absolute_error(y_away, away_pred),\n",
    "        'home_r2': r2_score(y_home, home_pred),\n",
    "        'away_r2': r2_score(y_away, away_pred),\n",
    "    }\n",
    "    \n",
    "    # Combined metrics\n",
    "    all_pred = np.concatenate([home_pred, away_pred])\n",
    "    all_actual = np.concatenate([y_home, y_away])\n",
    "    metrics['combined_rmse'] = np.sqrt(mean_squared_error(all_actual, all_pred))\n",
    "    metrics['combined_mae'] = mean_absolute_error(all_actual, all_pred)\n",
    "    metrics['combined_r2'] = r2_score(all_actual, all_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "baseline_metrics = evaluate_models(baseline_home, baseline_away, X_val, y_home_val, y_away_val)\n",
    "\n",
    "print(\"\\n Baseline Validation Performance\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nHome Goals:\")\n",
    "print(f\"  RMSE: {baseline_metrics['home_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['home_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['home_r2']:.4f}\")\n",
    "print(f\"\\nAway Goals:\")\n",
    "print(f\"  RMSE: {baseline_metrics['away_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['away_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['away_r2']:.4f}\")\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {baseline_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['combined_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551666b3",
   "metadata": {},
   "source": [
    "## 4. Random Search Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter distributions for random search\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', 0.5, 0.8],\n",
    "}\n",
    "\n",
    "print(f\"Parameters to tune: {len(param_distributions)}\")\n",
    "for k, v in param_distributions.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(X_train, y_train, X_val, y_val, param_dist, n_iter=50):\n",
    "    \"\"\"\n",
    "    Perform random search for hyperparameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # Sample random parameters\n",
    "        params = {k: np.random.choice(v) for k, v in param_dist.items()}\n",
    "        params['random_state'] = 42\n",
    "        params['n_jobs'] = -1\n",
    "        params['bootstrap'] = True\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model = RandomForestRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            train_pred = model.predict(X_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            \n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            \n",
    "            result = {\n",
    "                'iteration': i + 1,\n",
    "                'train_rmse': train_rmse,\n",
    "                'val_rmse': val_rmse,\n",
    "                'overfit_ratio': train_rmse / val_rmse if val_rmse > 0 else 0,\n",
    "                **params\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Iteration {i + 1}/{n_iter}: Val RMSE = {val_rmse:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Iteration {i + 1} failed: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Starting Random Search for Home Goals...\")\n",
    "home_random_results = random_search(X_train, y_home_train, X_val, y_home_val, param_distributions, n_iter=50)\n",
    "\n",
    "print(\"\\nStarting Random Search for Away Goals...\")\n",
    "away_random_results = random_search(X_train, y_away_train, X_val, y_away_val, param_distributions, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best configurations\n",
    "best_home_idx = home_random_results['val_rmse'].idxmin()\n",
    "best_away_idx = away_random_results['val_rmse'].idxmin()\n",
    "\n",
    "best_home_config = home_random_results.loc[best_home_idx]\n",
    "best_away_config = away_random_results.loc[best_away_idx]\n",
    "\n",
    "print(\"\\nBest Home Goals Configuration:\")\n",
    "print(f\"  Val RMSE: {best_home_config['val_rmse']:.4f}\")\n",
    "for param in param_distributions.keys():\n",
    "    print(f\"  {param}: {best_home_config[param]}\")\n",
    "\n",
    "print(\"\\nBest Away Goals Configuration:\")\n",
    "print(f\"  Val RMSE: {best_away_config['val_rmse']:.4f}\")\n",
    "for param in param_distributions.keys():\n",
    "    print(f\"  {param}: {best_away_config[param]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de157f",
   "metadata": {},
   "source": [
    "## 5. Grid Search (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune around best parameters found\n",
    "fine_tune_params = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [8, 10, 12, 15],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "}\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def grid_search(X_train, y_train, X_val, y_val, param_grid):\n",
    "    \"\"\"Perform grid search for hyperparameters.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Generate all combinations\n",
    "    keys = list(param_grid.keys())\n",
    "    combinations = list(product(*[param_grid[k] for k in keys]))\n",
    "    \n",
    "    print(f\"Testing {len(combinations)} combinations...\")\n",
    "    \n",
    "    for i, combo in enumerate(combinations):\n",
    "        params = dict(zip(keys, combo))\n",
    "        params['random_state'] = 42\n",
    "        params['n_jobs'] = -1\n",
    "        params['max_features'] = 'sqrt'\n",
    "        \n",
    "        try:\n",
    "            model = RandomForestRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            val_pred = model.predict(X_val)\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            \n",
    "            results.append({'val_rmse': val_rmse, **params})\n",
    "            \n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  Progress: {i + 1}/{len(combinations)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Combo {i + 1} failed: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Grid Search for Home Goals:\")\n",
    "home_grid_results = grid_search(X_train, y_home_train, X_val, y_home_val, fine_tune_params)\n",
    "\n",
    "print(\"\\nGrid Search for Away Goals:\")\n",
    "away_grid_results = grid_search(X_train, y_away_train, X_val, y_away_val, fine_tune_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc416bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best from grid search\n",
    "best_home_grid = home_grid_results.loc[home_grid_results['val_rmse'].idxmin()]\n",
    "best_away_grid = away_grid_results.loc[away_grid_results['val_rmse'].idxmin()]\n",
    "\n",
    "print(\"Best Grid Search Results:\")\n",
    "print(f\"\\nHome Goals - Val RMSE: {best_home_grid['val_rmse']:.4f}\")\n",
    "print(f\"Away Goals - Val RMSE: {best_away_grid['val_rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a8311",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fde02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best parameters for cross-validation\n",
    "best_params = {\n",
    "    'n_estimators': int(best_home_grid['n_estimators']),\n",
    "    'max_depth': int(best_home_grid['max_depth']) if best_home_grid['max_depth'] else None,\n",
    "    'min_samples_split': int(best_home_grid['min_samples_split']),\n",
    "    'min_samples_leaf': int(best_home_grid['min_samples_leaf']),\n",
    "    'max_features': 'sqrt',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "\n",
    "# 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X_full = pd.concat([X_train, X_val])\n",
    "y_home_full = pd.concat([y_home_train, y_home_val])\n",
    "y_away_full = pd.concat([y_away_train, y_away_val])\n",
    "\n",
    "# Cross-validation for home goals\n",
    "home_cv_scores = cross_val_score(\n",
    "    RandomForestRegressor(**best_params),\n",
    "    X_full, y_home_full,\n",
    "    cv=kfold,\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Cross-validation for away goals\n",
    "away_cv_scores = cross_val_score(\n",
    "    RandomForestRegressor(**best_params),\n",
    "    X_full, y_away_full,\n",
    "    cv=kfold,\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(f\"\\nHome Goals RMSE: {-home_cv_scores.mean():.4f} (+/- {home_cv_scores.std():.4f})\")\n",
    "print(f\"Away Goals RMSE: {-away_cv_scores.mean():.4f} (+/- {away_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f08da",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5efe40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models with best params\n",
    "final_home = RandomForestRegressor(**best_params)\n",
    "final_home.fit(X_full, y_home_full)\n",
    "\n",
    "final_away = RandomForestRegressor(**best_params)\n",
    "final_away.fit(X_full, y_away_full)\n",
    "\n",
    "# Feature importance\n",
    "home_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_home.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "away_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_away.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Features for Home Goals:\")\n",
    "print(home_importance.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 10 Features for Away Goals:\")\n",
    "print(away_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Home goals\n",
    "axes[0].barh(home_importance['feature'].head(10)[::-1], \n",
    "             home_importance['importance'].head(10)[::-1])\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Top 10 Features - Home Goals')\n",
    "\n",
    "# Away goals\n",
    "axes[1].barh(away_importance['feature'].head(10)[::-1], \n",
    "             away_importance['importance'].head(10)[::-1])\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('Top 10 Features - Away Goals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c917d2d",
   "metadata": {},
   "source": [
    "## 8. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = evaluate_models(final_home, final_away, X_test, y_home_test, y_away_test)\n",
    "\n",
    "print(\"\\n Final Test Set Performance\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nHome Goals:\")\n",
    "print(f\"  RMSE: {test_metrics['home_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['home_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['home_r2']:.4f}\")\n",
    "print(f\"\\nAway Goals:\")\n",
    "print(f\"  RMSE: {test_metrics['away_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['away_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['away_r2']:.4f}\")\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {test_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['combined_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs tuned\n",
    "print(\"\\n Improvement Over Baseline\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "baseline_test = evaluate_models(baseline_home, baseline_away, X_test, y_home_test, y_away_test)\n",
    "\n",
    "home_improvement = (baseline_test['home_rmse'] - test_metrics['home_rmse']) / baseline_test['home_rmse'] * 100\n",
    "away_improvement = (baseline_test['away_rmse'] - test_metrics['away_rmse']) / baseline_test['away_rmse'] * 100\n",
    "combined_improvement = (baseline_test['combined_rmse'] - test_metrics['combined_rmse']) / baseline_test['combined_rmse'] * 100\n",
    "\n",
    "print(f\"Home Goals RMSE: {baseline_test['home_rmse']:.4f} -> {test_metrics['home_rmse']:.4f} ({home_improvement:+.1f}%)\")\n",
    "print(f\"Away Goals RMSE: {baseline_test['away_rmse']:.4f} -> {test_metrics['away_rmse']:.4f} ({away_improvement:+.1f}%)\")\n",
    "print(f\"Combined RMSE:   {baseline_test['combined_rmse']:.4f} -> {test_metrics['combined_rmse']:.4f} ({combined_improvement:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b11bb",
   "metadata": {},
   "source": [
    "## 9. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "output_dir = 'output/models/random_forest'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "with open(f'{output_dir}/random_forest_home.pkl', 'wb') as f:\n",
    "    pickle.dump(final_home, f)\n",
    "\n",
    "with open(f'{output_dir}/random_forest_away.pkl', 'wb') as f:\n",
    "    pickle.dump(final_away, f)\n",
    "\n",
    "# Save best parameters\n",
    "model_info = {\n",
    "    'model_type': 'RandomForestRegressor',\n",
    "    'best_params': best_params,\n",
    "    'test_metrics': test_metrics,\n",
    "    'cv_home_rmse': float(-home_cv_scores.mean()),\n",
    "    'cv_away_rmse': float(-away_cv_scores.mean()),\n",
    "    'feature_cols': feature_cols,\n",
    "    'trained_at': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/random_forest_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Models saved to {output_dir}/\")\n",
    "print(f\"  - random_forest_home.pkl\")\n",
    "print(f\"  - random_forest_away.pkl\")\n",
    "print(f\"  - random_forest_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bada8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" RANDOM FOREST TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nFinal Test Performance:\")\n",
    "print(f\"  Combined RMSE: {test_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  Combined MAE:  {test_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  Combined R²:   {test_metrics['combined_r2']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
