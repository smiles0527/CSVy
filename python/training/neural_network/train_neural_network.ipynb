{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5349e6",
   "metadata": {},
   "source": [
    "# Model 6: Neural Network - Training and Hyperparameter Tuning\n",
    "\n",
    "This notebook trains neural network models for hockey goal prediction using sklearn's MLPRegressor.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Setup and Imports\n",
    "2. Load Data\n",
    "3. Data Preprocessing\n",
    "4. Baseline Neural Network\n",
    "5. Random Search Hyperparameter Tuning\n",
    "6. Grid Search (Fine-tuning)\n",
    "7. Learning Curve Analysis\n",
    "8. Final Model Evaluation\n",
    "9. Save Best Model\n",
    "\n",
    "## Neural Network Considerations\n",
    "\n",
    "- **Feature Scaling**: Critical for neural networks\n",
    "- **Architecture**: Number/size of hidden layers\n",
    "- **Regularization**: L2 penalty (alpha), early stopping\n",
    "- **Activation**: ReLU typically works well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815bc7e",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a30220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reliably set cwd to the python/ folder\n",
    "_cwd = pathlib.Path(os.path.abspath('')).resolve()\n",
    "if (_cwd / 'python').is_dir():\n",
    "    _python_dir = _cwd / 'python'\n",
    "elif _cwd.name == 'neural_network' and (_cwd.parent.parent / 'data').is_dir():\n",
    "    _python_dir = _cwd.parent.parent\n",
    "elif _cwd.name == 'training' and (_cwd.parent / 'data').is_dir():\n",
    "    _python_dir = _cwd.parent\n",
    "elif (_cwd / 'data').is_dir():\n",
    "    _python_dir = _cwd\n",
    "else:\n",
    "    raise RuntimeError(f'Cannot locate python/ directory from {_cwd}')\n",
    "\n",
    "os.chdir(_python_dir)\n",
    "sys.path.insert(0, str(_python_dir))\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"CWD: {os.getcwd()}\")\n",
    "print(\"Scikit-learn MLPRegressor ready\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameter configuration\n",
    "config_path = '../config/hyperparams/model6_neural_network.yaml'\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(f\"Loaded config: {config.get('model_name', 'Neural Network')}\")\n",
    "    print(f\"Description: {config.get('description', 'MLP for goal prediction')}\")\n",
    "else:\n",
    "    print(f\"Config not found at {config_path}, using defaults\")\n",
    "    config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dd245",
   "metadata": {},
   "source": [
    "## 2. Load or Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f939064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real data, otherwise generate synthetic\n",
    "data_path = 'data/hockey_features.csv'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    print(f\"Loaded {len(data)} games from {data_path}\")\n",
    "else:\n",
    "    print(\"Generating synthetic hockey data for demonstration...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_games = 2000\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        # Team strength metrics\n",
    "        'home_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "        'away_win_pct': np.random.uniform(0.3, 0.7, n_games),\n",
    "        'home_points_pct': np.random.uniform(0.4, 0.8, n_games),\n",
    "        'away_points_pct': np.random.uniform(0.4, 0.8, n_games),\n",
    "        \n",
    "        # Offensive metrics\n",
    "        'home_goals_avg': np.random.uniform(2.5, 3.8, n_games),\n",
    "        'away_goals_avg': np.random.uniform(2.5, 3.8, n_games),\n",
    "        'home_shots_avg': np.random.uniform(28, 35, n_games),\n",
    "        'away_shots_avg': np.random.uniform(28, 35, n_games),\n",
    "        \n",
    "        # Defensive metrics\n",
    "        'home_goals_against_avg': np.random.uniform(2.2, 3.5, n_games),\n",
    "        'away_goals_against_avg': np.random.uniform(2.2, 3.5, n_games),\n",
    "        'home_save_pct': np.random.uniform(0.88, 0.93, n_games),\n",
    "        'away_save_pct': np.random.uniform(0.88, 0.93, n_games),\n",
    "        \n",
    "        # Special teams\n",
    "        'home_pp_pct': np.random.uniform(0.15, 0.28, n_games),\n",
    "        'away_pp_pct': np.random.uniform(0.15, 0.28, n_games),\n",
    "        'home_pk_pct': np.random.uniform(0.75, 0.88, n_games),\n",
    "        'away_pk_pct': np.random.uniform(0.75, 0.88, n_games),\n",
    "        \n",
    "        # Context\n",
    "        'home_rest_days': np.random.randint(1, 5, n_games),\n",
    "        'away_rest_days': np.random.randint(1, 5, n_games),\n",
    "        'home_b2b': np.random.binomial(1, 0.15, n_games),\n",
    "        'away_b2b': np.random.binomial(1, 0.15, n_games),\n",
    "        \n",
    "        # Recent form (last 5 games)\n",
    "        'home_goals_last5': np.random.uniform(2.0, 4.0, n_games),\n",
    "        'away_goals_last5': np.random.uniform(2.0, 4.0, n_games),\n",
    "        'home_wins_last5': np.random.randint(0, 6, n_games),\n",
    "        'away_wins_last5': np.random.randint(0, 6, n_games),\n",
    "    })\n",
    "    \n",
    "    # Generate realistic goal totals\n",
    "    home_advantage = 0.35\n",
    "    \n",
    "    data['home_goals'] = np.round(\n",
    "        data['home_goals_avg'] * 0.3 +\n",
    "        data['home_goals_last5'] * 0.2 +\n",
    "        (4 - data['away_goals_against_avg']) * 0.3 +\n",
    "        data['home_pp_pct'] * 3 +\n",
    "        home_advantage +\n",
    "        (data['home_rest_days'] - data['away_rest_days']) * 0.1 +\n",
    "        np.random.normal(0, 0.8, n_games)\n",
    "    ).clip(0, 9).astype(int)\n",
    "    \n",
    "    data['away_goals'] = np.round(\n",
    "        data['away_goals_avg'] * 0.3 +\n",
    "        data['away_goals_last5'] * 0.2 +\n",
    "        (4 - data['home_goals_against_avg']) * 0.3 +\n",
    "        data['away_pp_pct'] * 3 +\n",
    "        np.random.normal(0, 0.8, n_games)\n",
    "    ).clip(0, 9).astype(int)\n",
    "    \n",
    "    print(f\"Generated {n_games} synthetic games\")\n",
    "\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "print(f\"Home goals mean: {data['home_goals'].mean():.2f}\")\n",
    "print(f\"Away goals mean: {data['away_goals'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and targets\n",
    "target_cols = ['home_goals', 'away_goals']\n",
    "exclude_cols = target_cols + ['home_team', 'away_team', 'date', 'game_id', 'season']\n",
    "\n",
    "feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols[:10]}...\")\n",
    "\n",
    "X = data[feature_cols]\n",
    "y_home = data['home_goals']\n",
    "y_away = data['away_goals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b18f8",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation/test split (60/20/20)\n",
    "X_trainval, X_test, y_home_trainval, y_home_test, y_away_trainval, y_away_test = train_test_split(\n",
    "    X, y_home, y_away, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_home_train, y_home_val, y_away_train, y_away_val = train_test_split(\n",
    "    X_trainval, y_home_trainval, y_away_trainval, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} games\")\n",
    "print(f\"Validation set: {len(X_val)} games\")\n",
    "print(f\"Test set: {len(X_test)} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (CRITICAL for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")\n",
    "print(f\"Train mean: {X_train_scaled.mean():.4f}, std: {X_train_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb4279",
   "metadata": {},
   "source": [
    "## 4. Baseline Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "default_params = {\n",
    "    'hidden_layer_sizes': (100, 50),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'alpha': 0.001,  # L2 regularization\n",
    "    'learning_rate': 'adaptive',\n",
    "    'learning_rate_init': 0.001,\n",
    "    'max_iter': 500,\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.1,\n",
    "    'n_iter_no_change': 20,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "print(\"Default Neural Network Parameters:\")\n",
    "for k, v in default_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models\n",
    "print(\"Training baseline home goals model...\")\n",
    "baseline_home = MLPRegressor(**default_params)\n",
    "baseline_home.fit(X_train_scaled, y_home_train)\n",
    "print(f\"  Converged in {baseline_home.n_iter_} iterations\")\n",
    "\n",
    "print(\"Training baseline away goals model...\")\n",
    "baseline_away = MLPRegressor(**default_params)\n",
    "baseline_away.fit(X_train_scaled, y_away_train)\n",
    "print(f\"  Converged in {baseline_away.n_iter_} iterations\")\n",
    "\n",
    "print(\"\\nBaseline models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_models(home_model, away_model, X, y_home, y_away):\n",
    "    \"\"\"Evaluate both models and return combined metrics.\"\"\"\n",
    "    home_pred = home_model.predict(X)\n",
    "    away_pred = away_model.predict(X)\n",
    "    \n",
    "    metrics = {\n",
    "        'home_rmse': np.sqrt(mean_squared_error(y_home, home_pred)),\n",
    "        'away_rmse': np.sqrt(mean_squared_error(y_away, away_pred)),\n",
    "        'home_mae': mean_absolute_error(y_home, home_pred),\n",
    "        'away_mae': mean_absolute_error(y_away, away_pred),\n",
    "        'home_r2': r2_score(y_home, home_pred),\n",
    "        'away_r2': r2_score(y_away, away_pred),\n",
    "    }\n",
    "    \n",
    "    # Combined metrics\n",
    "    all_pred = np.concatenate([home_pred, away_pred])\n",
    "    all_actual = np.concatenate([y_home, y_away])\n",
    "    metrics['combined_rmse'] = np.sqrt(mean_squared_error(all_actual, all_pred))\n",
    "    metrics['combined_mae'] = mean_absolute_error(all_actual, all_pred)\n",
    "    metrics['combined_r2'] = r2_score(all_actual, all_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "baseline_metrics = evaluate_models(baseline_home, baseline_away, X_val_scaled, y_home_val, y_away_val)\n",
    "\n",
    "print(\"\\n Baseline Validation Performance\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nHome Goals:\")\n",
    "print(f\"  RMSE: {baseline_metrics['home_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['home_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['home_r2']:.4f}\")\n",
    "print(f\"\\nAway Goals:\")\n",
    "print(f\"  RMSE: {baseline_metrics['away_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['away_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['away_r2']:.4f}\")\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {baseline_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {baseline_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  R²:   {baseline_metrics['combined_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec2832",
   "metadata": {},
   "source": [
    "## 5. Random Search Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0382bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter distributions for random search\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (50,),\n",
    "        (100,),\n",
    "        (50, 25),\n",
    "        (100, 50),\n",
    "        (128, 64),\n",
    "        (100, 50, 25),\n",
    "        (128, 64, 32),\n",
    "        (200, 100),\n",
    "    ],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate_init': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128, 'auto'],\n",
    "}\n",
    "\n",
    "print(f\"Parameters to tune: {len(param_distributions)}\")\n",
    "for k, v in param_distributions.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_nn(X_train, y_train, X_val, y_val, param_dist, n_iter=30):\n",
    "    \"\"\"\n",
    "    Perform random search for neural network hyperparameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # Sample random parameters\n",
    "        params = {k: np.random.choice(v) if k != 'hidden_layer_sizes' else v[np.random.randint(len(v))] \n",
    "                  for k, v in param_dist.items()}\n",
    "        params['solver'] = 'adam'\n",
    "        params['max_iter'] = 300\n",
    "        params['early_stopping'] = True\n",
    "        params['validation_fraction'] = 0.1\n",
    "        params['n_iter_no_change'] = 15\n",
    "        params['random_state'] = 42\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model = MLPRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            train_pred = model.predict(X_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            \n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            \n",
    "            result = {\n",
    "                'iteration': i + 1,\n",
    "                'train_rmse': train_rmse,\n",
    "                'val_rmse': val_rmse,\n",
    "                'n_iter': model.n_iter_,\n",
    "                'overfit_ratio': train_rmse / val_rmse if val_rmse > 0 else 0,\n",
    "                **{k: str(v) for k, v in params.items()}\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            if (i + 1) % 5 == 0:\n",
    "                print(f\"  Iteration {i + 1}/{n_iter}: Val RMSE = {val_rmse:.4f} (arch: {params['hidden_layer_sizes']})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Iteration {i + 1} failed: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Starting Random Search for Home Goals...\")\n",
    "home_random_results = random_search_nn(X_train_scaled, y_home_train, X_val_scaled, y_home_val, param_distributions, n_iter=30)\n",
    "\n",
    "print(\"\\nStarting Random Search for Away Goals...\")\n",
    "away_random_results = random_search_nn(X_train_scaled, y_away_train, X_val_scaled, y_away_val, param_distributions, n_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best configurations\n",
    "best_home_idx = home_random_results['val_rmse'].idxmin()\n",
    "best_away_idx = away_random_results['val_rmse'].idxmin()\n",
    "\n",
    "best_home_config = home_random_results.loc[best_home_idx]\n",
    "best_away_config = away_random_results.loc[best_away_idx]\n",
    "\n",
    "print(\"\\nBest Home Goals Configuration:\")\n",
    "print(f\"  Val RMSE: {best_home_config['val_rmse']:.4f}\")\n",
    "for param in param_distributions.keys():\n",
    "    print(f\"  {param}: {best_home_config[param]}\")\n",
    "\n",
    "print(\"\\nBest Away Goals Configuration:\")\n",
    "print(f\"  Val RMSE: {best_away_config['val_rmse']:.4f}\")\n",
    "for param in param_distributions.keys():\n",
    "    print(f\"  {param}: {best_away_config[param]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6af5c",
   "metadata": {},
   "source": [
    "## 6. Grid Search (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune around best architecture\n",
    "from itertools import product\n",
    "\n",
    "fine_tune_params = {\n",
    "    'hidden_layer_sizes': [(100, 50), (128, 64), (100, 50, 25)],\n",
    "    'alpha': [0.0005, 0.001, 0.005],\n",
    "    'learning_rate_init': [0.0005, 0.001, 0.002],\n",
    "}\n",
    "\n",
    "def grid_search_nn(X_train, y_train, X_val, y_val, param_grid):\n",
    "    \"\"\"Perform grid search for neural network hyperparameters.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Generate all combinations\n",
    "    keys = list(param_grid.keys())\n",
    "    combinations = list(product(*[param_grid[k] for k in keys]))\n",
    "    \n",
    "    print(f\"Testing {len(combinations)} combinations...\")\n",
    "    \n",
    "    for i, combo in enumerate(combinations):\n",
    "        params = dict(zip(keys, combo))\n",
    "        params['solver'] = 'adam'\n",
    "        params['activation'] = 'relu'\n",
    "        params['max_iter'] = 500\n",
    "        params['early_stopping'] = True\n",
    "        params['validation_fraction'] = 0.1\n",
    "        params['n_iter_no_change'] = 20\n",
    "        params['random_state'] = 42\n",
    "        \n",
    "        try:\n",
    "            model = MLPRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            val_pred = model.predict(X_val)\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            \n",
    "            result = {'val_rmse': val_rmse, 'n_iter': model.n_iter_}\n",
    "            result.update({k: str(v) for k, v in params.items() if k in keys})\n",
    "            results.append(result)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Progress: {i + 1}/{len(combinations)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Combo {i + 1} failed: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Grid Search for Home Goals:\")\n",
    "home_grid_results = grid_search_nn(X_train_scaled, y_home_train, X_val_scaled, y_home_val, fine_tune_params)\n",
    "\n",
    "print(\"\\nGrid Search for Away Goals:\")\n",
    "away_grid_results = grid_search_nn(X_train_scaled, y_away_train, X_val_scaled, y_away_val, fine_tune_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab66a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best from grid search\n",
    "best_home_grid = home_grid_results.loc[home_grid_results['val_rmse'].idxmin()]\n",
    "best_away_grid = away_grid_results.loc[away_grid_results['val_rmse'].idxmin()]\n",
    "\n",
    "print(\"Best Grid Search Results:\")\n",
    "print(f\"\\nHome Goals - Val RMSE: {best_home_grid['val_rmse']:.4f}\")\n",
    "print(f\"  Architecture: {best_home_grid['hidden_layer_sizes']}\")\n",
    "print(f\"  Alpha: {best_home_grid['alpha']}\")\n",
    "print(f\"  Learning rate: {best_home_grid['learning_rate_init']}\")\n",
    "\n",
    "print(f\"\\nAway Goals - Val RMSE: {best_away_grid['val_rmse']:.4f}\")\n",
    "print(f\"  Architecture: {best_away_grid['hidden_layer_sizes']}\")\n",
    "print(f\"  Alpha: {best_away_grid['alpha']}\")\n",
    "print(f\"  Learning rate: {best_away_grid['learning_rate_init']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634cf6d",
   "metadata": {},
   "source": [
    "## 7. Learning Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "# Parse best parameters (stored as strings)\n",
    "import ast\n",
    "\n",
    "best_params = {\n",
    "    'hidden_layer_sizes': ast.literal_eval(best_home_grid['hidden_layer_sizes']),\n",
    "    'alpha': float(best_home_grid['alpha']),\n",
    "    'learning_rate_init': float(best_home_grid['learning_rate_init']),\n",
    "    'solver': 'adam',\n",
    "    'activation': 'relu',\n",
    "    'max_iter': 1000,\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.1,\n",
    "    'n_iter_no_change': 30,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve analysis\n",
    "X_full_scaled = np.vstack([X_train_scaled, X_val_scaled])\n",
    "y_home_full = pd.concat([y_home_train, y_home_val])\n",
    "y_away_full = pd.concat([y_away_train, y_away_val])\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    MLPRegressor(**best_params),\n",
    "    X_full_scaled, y_home_full,\n",
    "    train_sizes=np.linspace(0.2, 1.0, 5),\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, -train_scores.mean(axis=1), 'o-', label='Training RMSE')\n",
    "plt.plot(train_sizes, -val_scores.mean(axis=1), 'o-', label='Validation RMSE')\n",
    "plt.fill_between(train_sizes, \n",
    "                 -train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                 -train_scores.mean(axis=1) + train_scores.std(axis=1),\n",
    "                 alpha=0.2)\n",
    "plt.fill_between(train_sizes, \n",
    "                 -val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                 -val_scores.mean(axis=1) + val_scores.std(axis=1),\n",
    "                 alpha=0.2)\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Learning Curve - Neural Network (Home Goals)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "home_cv_scores = cross_val_score(\n",
    "    MLPRegressor(**best_params),\n",
    "    X_full_scaled, y_home_full,\n",
    "    cv=kfold,\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "away_cv_scores = cross_val_score(\n",
    "    MLPRegressor(**best_params),\n",
    "    X_full_scaled, y_away_full,\n",
    "    cv=kfold,\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(f\"\\nHome Goals RMSE: {-home_cv_scores.mean():.4f} (+/- {home_cv_scores.std():.4f})\")\n",
    "print(f\"Away Goals RMSE: {-away_cv_scores.mean():.4f} (+/- {away_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ae7cc",
   "metadata": {},
   "source": [
    "## 8. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models on all training + validation data\n",
    "print(\"Training final models...\")\n",
    "\n",
    "final_home = MLPRegressor(**best_params)\n",
    "final_home.fit(X_full_scaled, y_home_full)\n",
    "print(f\"  Home model converged in {final_home.n_iter_} iterations\")\n",
    "\n",
    "final_away = MLPRegressor(**best_params)\n",
    "final_away.fit(X_full_scaled, y_away_full)\n",
    "print(f\"  Away model converged in {final_away.n_iter_} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc525ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = evaluate_models(final_home, final_away, X_test_scaled, y_home_test, y_away_test)\n",
    "\n",
    "print(\"\\n Final Test Set Performance\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nHome Goals:\")\n",
    "print(f\"  RMSE: {test_metrics['home_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['home_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['home_r2']:.4f}\")\n",
    "print(f\"\\nAway Goals:\")\n",
    "print(f\"  RMSE: {test_metrics['away_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['away_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['away_r2']:.4f}\")\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {test_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['combined_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs tuned\n",
    "print(\"\\n Improvement Over Baseline\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "baseline_test = evaluate_models(baseline_home, baseline_away, X_test_scaled, y_home_test, y_away_test)\n",
    "\n",
    "home_improvement = (baseline_test['home_rmse'] - test_metrics['home_rmse']) / baseline_test['home_rmse'] * 100\n",
    "away_improvement = (baseline_test['away_rmse'] - test_metrics['away_rmse']) / baseline_test['away_rmse'] * 100\n",
    "combined_improvement = (baseline_test['combined_rmse'] - test_metrics['combined_rmse']) / baseline_test['combined_rmse'] * 100\n",
    "\n",
    "print(f\"Home Goals RMSE: {baseline_test['home_rmse']:.4f} -> {test_metrics['home_rmse']:.4f} ({home_improvement:+.1f}%)\")\n",
    "print(f\"Away Goals RMSE: {baseline_test['away_rmse']:.4f} -> {test_metrics['away_rmse']:.4f} ({away_improvement:+.1f}%)\")\n",
    "print(f\"Combined RMSE:   {baseline_test['combined_rmse']:.4f} -> {test_metrics['combined_rmse']:.4f} ({combined_improvement:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "home_pred = final_home.predict(X_test_scaled)\n",
    "away_pred = final_away.predict(X_test_scaled)\n",
    "\n",
    "# Home goals\n",
    "axes[0].scatter(y_home_test, home_pred, alpha=0.5, edgecolor='k', linewidth=0.5)\n",
    "axes[0].plot([0, 8], [0, 8], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Home Goals')\n",
    "axes[0].set_ylabel('Predicted Home Goals')\n",
    "axes[0].set_title(f'Home Goals: RMSE = {test_metrics[\"home_rmse\"]:.4f}')\n",
    "\n",
    "# Away goals\n",
    "axes[1].scatter(y_away_test, away_pred, alpha=0.5, edgecolor='k', linewidth=0.5)\n",
    "axes[1].plot([0, 8], [0, 8], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Away Goals')\n",
    "axes[1].set_ylabel('Predicted Away Goals')\n",
    "axes[1].set_title(f'Away Goals: RMSE = {test_metrics[\"away_rmse\"]:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b024b",
   "metadata": {},
   "source": [
    "## 9. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "output_dir = 'output/models/neural_network'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save neural network models\n",
    "with open(f'{output_dir}/neural_network_home.pkl', 'wb') as f:\n",
    "    pickle.dump(final_home, f)\n",
    "\n",
    "with open(f'{output_dir}/neural_network_away.pkl', 'wb') as f:\n",
    "    pickle.dump(final_away, f)\n",
    "\n",
    "# Save scaler (required for inference)\n",
    "with open(f'{output_dir}/neural_network_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'model_type': 'MLPRegressor',\n",
    "    'best_params': {k: str(v) for k, v in best_params.items()},\n",
    "    'test_metrics': test_metrics,\n",
    "    'cv_home_rmse': float(-home_cv_scores.mean()),\n",
    "    'cv_home_std': float(home_cv_scores.std()),\n",
    "    'cv_away_rmse': float(-away_cv_scores.mean()),\n",
    "    'cv_away_std': float(away_cv_scores.std()),\n",
    "    'feature_cols': feature_cols,\n",
    "    'home_n_iter': int(final_home.n_iter_),\n",
    "    'away_n_iter': int(final_away.n_iter_),\n",
    "    'trained_at': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/neural_network_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Models saved to {output_dir}/\")\n",
    "print(f\"  - neural_network_home.pkl\")\n",
    "print(f\"  - neural_network_away.pkl\")\n",
    "print(f\"  - neural_network_scaler.pkl\")\n",
    "print(f\"  - neural_network_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(final_home.loss_curve_)\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss - Home Goals Model')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(final_away.loss_curve_)\n",
    "axes[1].set_xlabel('Iteration')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Training Loss - Away Goals Model')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c53e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" NEURAL NETWORK TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nArchitecture: {best_params['hidden_layer_sizes']}\")\n",
    "print(f\"Activation: {best_params['activation']}\")\n",
    "print(f\"Alpha (L2): {best_params['alpha']}\")\n",
    "print(f\"Learning Rate: {best_params['learning_rate_init']}\")\n",
    "print(f\"\\nFinal Test Performance:\")\n",
    "print(f\"  Combined RMSE: {test_metrics['combined_rmse']:.4f}\")\n",
    "print(f\"  Combined MAE:  {test_metrics['combined_mae']:.4f}\")\n",
    "print(f\"  Combined R²:   {test_metrics['combined_r2']:.4f}\")\n",
    "print(f\"\\nCross-Validation (5-fold):\")\n",
    "print(f\"  Home RMSE: {-home_cv_scores.mean():.4f} (+/- {home_cv_scores.std():.4f})\")\n",
    "print(f\"  Away RMSE: {-away_cv_scores.mean():.4f} (+/- {away_cv_scores.std():.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
