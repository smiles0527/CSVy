{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa88fd31",
   "metadata": {},
   "source": [
    "# Linear Regression Model for Hockey Goal Prediction\n",
    "\n",
    "This notebook implements the LinearRegressionModel and LinearGoalPredictor classes\n",
    "for predicting hockey game outcomes using linear regression with regularization.\n",
    "\n",
    "**Model 3** in our prediction pipeline.\n",
    "\n",
    "## Features\n",
    "- ElasticNet regularization (L1/L2 mix)\n",
    "- Polynomial feature expansion\n",
    "- Feature scaling (Standard/Robust)\n",
    "- Coefficient analysis and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad07fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d807f",
   "metadata": {},
   "source": [
    "## 1. LinearRegressionModel Class\n",
    "\n",
    "The core class supporting Ridge, Lasso, ElasticNet, and plain OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7579a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.linear_model import (\n",
    "    LinearRegressionModel,\n",
    "    LinearGoalPredictor,\n",
    "    grid_search_linear,\n",
    "    random_search_linear,\n",
    "    compare_regularization\n",
    ")\n",
    "\n",
    "# Display class signature\n",
    "print(\"LinearRegressionModel Parameters:\")\n",
    "print(\"- alpha: Regularization strength (0 = no regularization)\")\n",
    "print(\"- l1_ratio: 0.0 = Ridge (L2), 1.0 = Lasso (L1), 0.5 = ElasticNet\")\n",
    "print(\"- scaling: 'standard', 'robust', or None\")\n",
    "print(\"- poly_degree: 1 = linear, 2+ = polynomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2c1af",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Data for Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6edd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic hockey game data\n",
    "np.random.seed(42)\n",
    "n_games = 500\n",
    "\n",
    "# Features\n",
    "data = pd.DataFrame({\n",
    "    'home_elo': np.random.normal(1500, 100, n_games),\n",
    "    'away_elo': np.random.normal(1500, 100, n_games),\n",
    "    'home_recent_form': np.random.uniform(0, 1, n_games),\n",
    "    'away_recent_form': np.random.uniform(0, 1, n_games),\n",
    "    'home_rest_days': np.random.choice([1, 2, 3, 4, 5], n_games),\n",
    "    'away_rest_days': np.random.choice([1, 2, 3, 4, 5], n_games),\n",
    "    'home_avg_goals': np.random.normal(3.0, 0.5, n_games),\n",
    "    'away_avg_goals': np.random.normal(2.8, 0.5, n_games),\n",
    "    'home_avg_against': np.random.normal(2.7, 0.5, n_games),\n",
    "    'away_avg_against': np.random.normal(2.9, 0.5, n_games),\n",
    "})\n",
    "\n",
    "# Generate targets with some relationship to features\n",
    "home_base = (\n",
    "    0.5 * (data['home_elo'] - data['away_elo']) / 100 +\n",
    "    0.3 * data['home_recent_form'] +\n",
    "    0.5 * data['home_avg_goals'] -\n",
    "    0.2 * data['away_avg_goals'] +\n",
    "    0.1 * (data['home_rest_days'] - data['away_rest_days'])\n",
    ")\n",
    "\n",
    "away_base = (\n",
    "    0.5 * (data['away_elo'] - data['home_elo']) / 100 +\n",
    "    0.3 * data['away_recent_form'] +\n",
    "    0.5 * data['away_avg_goals'] -\n",
    "    0.2 * data['home_avg_goals'] +\n",
    "    0.1 * (data['away_rest_days'] - data['home_rest_days'])\n",
    ")\n",
    "\n",
    "# Add noise and clip to realistic values\n",
    "data['home_goals'] = np.maximum(0, np.round(2.8 + home_base + np.random.normal(0, 1, n_games))).astype(int)\n",
    "data['away_goals'] = np.maximum(0, np.round(2.6 + away_base + np.random.normal(0, 1, n_games))).astype(int)\n",
    "\n",
    "print(f\"Generated {len(data)} games\")\n",
    "print(f\"\\nSample data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "feature_cols = [col for col in data.columns if col not in ['home_goals', 'away_goals']]\n",
    "X = data[feature_cols]\n",
    "y_home = data['home_goals']\n",
    "y_away = data['away_goals']\n",
    "\n",
    "X_train, X_test, y_home_train, y_home_test = train_test_split(\n",
    "    X, y_home, test_size=0.2, random_state=42\n",
    ")\n",
    "_, _, y_away_train, y_away_test = train_test_split(\n",
    "    X, y_away, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} games\")\n",
    "print(f\"Test set: {len(X_test)} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a58e0b",
   "metadata": {},
   "source": [
    "## 3. Train Different Regularization Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ca45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression (L2)\n",
    "ridge_model = LinearRegressionModel(\n",
    "    alpha=1.0,\n",
    "    l1_ratio=0.0,  # Pure Ridge\n",
    "    scaling='standard',\n",
    "    name='ridge_home'\n",
    ")\n",
    "\n",
    "ridge_model.fit(X_train, y_home_train)\n",
    "ridge_metrics = ridge_model.evaluate(X_test, y_home_test)\n",
    "\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(f\"  RMSE: {ridge_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {ridge_metrics['mae']:.4f}\")\n",
    "print(f\"  R²:   {ridge_metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2860e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression (L1)\n",
    "lasso_model = LinearRegressionModel(\n",
    "    alpha=0.1,\n",
    "    l1_ratio=1.0,  # Pure Lasso\n",
    "    scaling='standard',\n",
    "    name='lasso_home'\n",
    ")\n",
    "\n",
    "lasso_model.fit(X_train, y_home_train)\n",
    "lasso_metrics = lasso_model.evaluate(X_test, y_home_test)\n",
    "\n",
    "print(\"Lasso Regression Results:\")\n",
    "print(f\"  RMSE: {lasso_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {lasso_metrics['mae']:.4f}\")\n",
    "print(f\"  R²:   {lasso_metrics['r2']:.4f}\")\n",
    "\n",
    "# Show selected features (non-zero coefficients)\n",
    "print(f\"\\nFeatures selected by Lasso: {len(lasso_model.get_nonzero_features())}\")\n",
    "print(lasso_model.get_nonzero_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet (L1 + L2)\n",
    "elasticnet_model = LinearRegressionModel(\n",
    "    alpha=0.1,\n",
    "    l1_ratio=0.5,  # Equal L1 and L2\n",
    "    scaling='standard',\n",
    "    name='elasticnet_home'\n",
    ")\n",
    "\n",
    "elasticnet_model.fit(X_train, y_home_train)\n",
    "elasticnet_metrics = elasticnet_model.evaluate(X_test, y_home_test)\n",
    "\n",
    "print(\"ElasticNet Regression Results:\")\n",
    "print(f\"  RMSE: {elasticnet_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {elasticnet_metrics['mae']:.4f}\")\n",
    "print(f\"  R²:   {elasticnet_metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5e054",
   "metadata": {},
   "source": [
    "## 4. Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52701c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polynomial features (quadratic terms)\n",
    "poly_model = LinearRegressionModel(\n",
    "    alpha=0.1,\n",
    "    l1_ratio=0.5,\n",
    "    poly_degree=2,  # Add quadratic terms\n",
    "    scaling='standard',\n",
    "    name='poly_elasticnet'\n",
    ")\n",
    "\n",
    "poly_model.fit(X_train, y_home_train)\n",
    "poly_metrics = poly_model.evaluate(X_test, y_home_test)\n",
    "\n",
    "print(\"Polynomial (degree=2) ElasticNet Results:\")\n",
    "print(f\"  RMSE: {poly_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {poly_metrics['mae']:.4f}\")\n",
    "print(f\"  R²:   {poly_metrics['r2']:.4f}\")\n",
    "print(f\"\\n  Original features: {poly_model.n_features_}\")\n",
    "print(f\"  After polynomial expansion: {poly_model.n_features_poly_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d53dd4",
   "metadata": {},
   "source": [
    "## 5. Coefficient Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients from the best model\n",
    "coefs = elasticnet_model.get_coefficients(top_n=15)\n",
    "print(\"Top 15 Most Important Coefficients:\")\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficients\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "coefs_to_plot = elasticnet_model.get_coefficients()\n",
    "colors = ['green' if c > 0 else 'red' for c in coefs_to_plot['coefficient']]\n",
    "\n",
    "ax.barh(coefs_to_plot['feature'], coefs_to_plot['coefficient'], color=colors)\n",
    "ax.set_xlabel('Coefficient Value')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_title('Linear Regression Coefficients')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37507e71",
   "metadata": {},
   "source": [
    "## 6. LinearGoalPredictor (Dual Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1611e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with full data for predictor\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the predictor\n",
    "predictor = LinearGoalPredictor(\n",
    "    alpha=0.1,\n",
    "    l1_ratio=0.5,\n",
    "    scaling='standard',\n",
    "    poly_degree=1\n",
    ")\n",
    "\n",
    "predictor.fit(train_df)\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "metrics = predictor.evaluate(test_df)\n",
    "\n",
    "print(\"LinearGoalPredictor Evaluation:\")\n",
    "print(f\"\\nHome Goals Prediction:\")\n",
    "print(f\"  RMSE: {metrics['home']['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {metrics['home']['mae']:.4f}\")\n",
    "print(f\"  R²:   {metrics['home']['r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nAway Goals Prediction:\")\n",
    "print(f\"  RMSE: {metrics['away']['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {metrics['away']['mae']:.4f}\")\n",
    "print(f\"  R²:   {metrics['away']['r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  RMSE: {metrics['combined']['rmse']:.4f}\")\n",
    "print(f\"  Win Accuracy: {metrics['win_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a single game\n",
    "sample_game = test_df.iloc[0]\n",
    "home_pred, away_pred = predictor.predict_goals(sample_game)\n",
    "\n",
    "print(\"Single Game Prediction:\")\n",
    "print(f\"  Predicted: {home_pred:.1f} - {away_pred:.1f}\")\n",
    "print(f\"  Actual:    {sample_game['home_goals']} - {sample_game['away_goals']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch predictions\n",
    "predictions = predictor.predict_batch(test_df)\n",
    "predictions['home_actual'] = test_df['home_goals'].values\n",
    "predictions['away_actual'] = test_df['away_goals'].values\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00059c05",
   "metadata": {},
   "source": [
    "## 7. Compare Regularization Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9dfa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Ridge, Lasso, ElasticNet across alpha values\n",
    "comparison = compare_regularization(\n",
    "    X_train, y_home_train,\n",
    "    alphas=[0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(\"Regularization Comparison:\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37734ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for model_name in ['Ridge', 'Lasso', 'ElasticNet']:\n",
    "    subset = comparison[comparison['model'] == model_name]\n",
    "    ax.plot(subset['alpha'], subset['rmse_mean'], marker='o', label=model_name)\n",
    "    ax.fill_between(\n",
    "        subset['alpha'],\n",
    "        subset['rmse_mean'] - subset['rmse_std'],\n",
    "        subset['rmse_mean'] + subset['rmse_std'],\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Alpha (Regularization Strength)')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Regularization Comparison')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2be659",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8223af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "cv_results = elasticnet_model.cross_validate(X, y_home, cv=5)\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(f\"  Mean RMSE: {cv_results['mean']:.4f} ± {cv_results['std']:.4f}\")\n",
    "print(f\"  Fold scores: {[f'{s:.4f}' for s in cv_results['scores']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0c3a6",
   "metadata": {},
   "source": [
    "## 9. Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89327486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictor\n",
    "predictor.save('../models/saved/linear_predictor')\n",
    "print(\"Predictor saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503634ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify\n",
    "loaded_predictor = LinearGoalPredictor.load('../models/saved/linear_predictor')\n",
    "loaded_metrics = loaded_predictor.evaluate(test_df)\n",
    "\n",
    "print(f\"Loaded predictor RMSE: {loaded_metrics['combined']['rmse']:.4f}\")\n",
    "print(f\"Original predictor RMSE: {metrics['combined']['rmse']:.4f}\")\n",
    "print(f\"Match: {abs(loaded_metrics['combined']['rmse'] - metrics['combined']['rmse']) < 0.0001}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477140f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Linear Regression model provides:\n",
    "- **Interpretable coefficients** - understand feature contributions\n",
    "- **Feature selection** - Lasso and ElasticNet can zero out unimportant features\n",
    "- **Regularization** - prevents overfitting with L1/L2 penalties\n",
    "- **Polynomial features** - capture non-linear relationships\n",
    "- **Fast training** - much faster than tree-based models\n",
    "\n",
    "### When to Use Linear Regression:\n",
    "- Baseline comparison with more complex models\n",
    "- When interpretability is important\n",
    "- Limited training data (less prone to overfitting)\n",
    "- Feature selection with Lasso/ElasticNet"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
